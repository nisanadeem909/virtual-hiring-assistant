{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.2.tar.gz (23.3 MB)\n",
      "     ---------------------------------------- 0.0/23.3 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/23.3 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/23.3 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/23.3 MB 163.8 kB/s eta 0:02:22\n",
      "     --------------------------------------- 0.0/23.3 MB 163.8 kB/s eta 0:02:22\n",
      "     --------------------------------------- 0.0/23.3 MB 163.4 kB/s eta 0:02:23\n",
      "     --------------------------------------- 0.1/23.3 MB 231.0 kB/s eta 0:01:41\n",
      "     --------------------------------------- 0.1/23.3 MB 327.2 kB/s eta 0:01:11\n",
      "     --------------------------------------- 0.2/23.3 MB 398.2 kB/s eta 0:00:59\n",
      "     --------------------------------------- 0.2/23.3 MB 478.0 kB/s eta 0:00:49\n",
      "     --------------------------------------- 0.2/23.3 MB 514.3 kB/s eta 0:00:45\n",
      "      -------------------------------------- 0.3/23.3 MB 593.9 kB/s eta 0:00:39\n",
      "      -------------------------------------- 0.4/23.3 MB 636.5 kB/s eta 0:00:36\n",
      "      -------------------------------------- 0.5/23.3 MB 741.3 kB/s eta 0:00:31\n",
      "     - ------------------------------------- 0.6/23.3 MB 942.5 kB/s eta 0:00:25\n",
      "     - -------------------------------------- 0.7/23.3 MB 1.1 MB/s eta 0:00:22\n",
      "     - -------------------------------------- 0.8/23.3 MB 1.1 MB/s eta 0:00:21\n",
      "     - -------------------------------------- 0.9/23.3 MB 1.2 MB/s eta 0:00:20\n",
      "     - -------------------------------------- 1.0/23.3 MB 1.2 MB/s eta 0:00:19\n",
      "     - -------------------------------------- 1.1/23.3 MB 1.2 MB/s eta 0:00:19\n",
      "     - -------------------------------------- 1.1/23.3 MB 1.2 MB/s eta 0:00:18\n",
      "     -- ------------------------------------- 1.2/23.3 MB 1.3 MB/s eta 0:00:18\n",
      "     -- ------------------------------------- 1.3/23.3 MB 1.3 MB/s eta 0:00:18\n",
      "     -- ------------------------------------- 1.4/23.3 MB 1.3 MB/s eta 0:00:17\n",
      "     -- ------------------------------------- 1.4/23.3 MB 1.3 MB/s eta 0:00:17\n",
      "     -- ------------------------------------- 1.4/23.3 MB 1.3 MB/s eta 0:00:17\n",
      "     -- ------------------------------------- 1.4/23.3 MB 1.3 MB/s eta 0:00:17\n",
      "     -- ------------------------------------- 1.4/23.3 MB 1.3 MB/s eta 0:00:17\n",
      "     -- ------------------------------------- 1.4/23.3 MB 1.3 MB/s eta 0:00:17\n",
      "     -- ------------------------------------- 1.4/23.3 MB 1.3 MB/s eta 0:00:17\n",
      "     -- ------------------------------------- 1.4/23.3 MB 1.3 MB/s eta 0:00:17\n",
      "     -- ------------------------------------- 1.5/23.3 MB 1.0 MB/s eta 0:00:22\n",
      "     -- ------------------------------------- 1.5/23.3 MB 1.0 MB/s eta 0:00:22\n",
      "     -- ------------------------------------- 1.5/23.3 MB 1.0 MB/s eta 0:00:22\n",
      "     -- ------------------------------------- 1.5/23.3 MB 1.0 MB/s eta 0:00:22\n",
      "     -- ------------------------------------- 1.5/23.3 MB 1.0 MB/s eta 0:00:22\n",
      "     -- ------------------------------------- 1.5/23.3 MB 1.0 MB/s eta 0:00:22\n",
      "     -- ------------------------------------- 1.5/23.3 MB 1.0 MB/s eta 0:00:22\n",
      "     -- ------------------------------------ 1.7/23.3 MB 974.1 kB/s eta 0:00:23\n",
      "     -- ------------------------------------ 1.7/23.3 MB 974.1 kB/s eta 0:00:23\n",
      "     --- ----------------------------------- 1.8/23.3 MB 980.0 kB/s eta 0:00:22\n",
      "     --- ------------------------------------ 2.0/23.3 MB 1.1 MB/s eta 0:00:21\n",
      "     --- ------------------------------------ 2.2/23.3 MB 1.1 MB/s eta 0:00:19\n",
      "     ---- ----------------------------------- 2.4/23.3 MB 1.2 MB/s eta 0:00:18\n",
      "     ---- ----------------------------------- 2.6/23.3 MB 1.3 MB/s eta 0:00:17\n",
      "     ---- ----------------------------------- 2.6/23.3 MB 1.3 MB/s eta 0:00:17\n",
      "     ----- ---------------------------------- 3.3/23.3 MB 1.5 MB/s eta 0:00:14\n",
      "     ----- ---------------------------------- 3.4/23.3 MB 1.5 MB/s eta 0:00:14\n",
      "     ----- ---------------------------------- 3.5/23.3 MB 1.5 MB/s eta 0:00:13\n",
      "     ------ --------------------------------- 3.5/23.3 MB 1.5 MB/s eta 0:00:13\n",
      "     ------ --------------------------------- 3.5/23.3 MB 1.5 MB/s eta 0:00:13\n",
      "     ------ --------------------------------- 3.5/23.3 MB 1.5 MB/s eta 0:00:13\n",
      "     ------ --------------------------------- 3.5/23.3 MB 1.5 MB/s eta 0:00:13\n",
      "     ------ --------------------------------- 3.5/23.3 MB 1.5 MB/s eta 0:00:13\n",
      "     ------ --------------------------------- 3.5/23.3 MB 1.5 MB/s eta 0:00:13\n",
      "     ------ --------------------------------- 3.5/23.3 MB 1.5 MB/s eta 0:00:13\n",
      "     ------ --------------------------------- 3.6/23.3 MB 1.4 MB/s eta 0:00:15\n",
      "     ------- -------------------------------- 4.2/23.3 MB 1.6 MB/s eta 0:00:13\n",
      "     ------- -------------------------------- 4.3/23.3 MB 1.6 MB/s eta 0:00:13\n",
      "     ------- -------------------------------- 4.3/23.3 MB 1.6 MB/s eta 0:00:13\n",
      "     ------- -------------------------------- 4.4/23.3 MB 1.6 MB/s eta 0:00:13\n",
      "     ------- -------------------------------- 4.5/23.3 MB 1.6 MB/s eta 0:00:12\n",
      "     ------- -------------------------------- 4.6/23.3 MB 1.6 MB/s eta 0:00:12\n",
      "     -------- ------------------------------- 4.7/23.3 MB 1.6 MB/s eta 0:00:12\n",
      "     -------- ------------------------------- 4.8/23.3 MB 1.6 MB/s eta 0:00:12\n",
      "     -------- ------------------------------- 4.8/23.3 MB 1.6 MB/s eta 0:00:12\n",
      "     -------- ------------------------------- 4.9/23.3 MB 1.6 MB/s eta 0:00:12\n",
      "     -------- ------------------------------- 5.0/23.3 MB 1.6 MB/s eta 0:00:12\n",
      "     -------- ------------------------------- 5.1/23.3 MB 1.6 MB/s eta 0:00:12\n",
      "     -------- ------------------------------- 5.2/23.3 MB 1.6 MB/s eta 0:00:12\n",
      "     --------- ------------------------------ 5.3/23.3 MB 1.6 MB/s eta 0:00:12\n",
      "     --------- ------------------------------ 5.4/23.3 MB 1.6 MB/s eta 0:00:12\n",
      "     --------- ------------------------------ 5.4/23.3 MB 1.6 MB/s eta 0:00:12\n",
      "     --------- ------------------------------ 5.5/23.3 MB 1.6 MB/s eta 0:00:12\n",
      "     --------- ------------------------------ 5.6/23.3 MB 1.6 MB/s eta 0:00:12\n",
      "     --------- ------------------------------ 5.7/23.3 MB 1.6 MB/s eta 0:00:12\n",
      "     --------- ------------------------------ 5.7/23.3 MB 1.6 MB/s eta 0:00:11\n",
      "     ---------- ----------------------------- 5.8/23.3 MB 1.6 MB/s eta 0:00:11\n",
      "     ---------- ----------------------------- 5.9/23.3 MB 1.6 MB/s eta 0:00:11\n",
      "     ---------- ----------------------------- 6.0/23.3 MB 1.6 MB/s eta 0:00:11\n",
      "     ---------- ----------------------------- 6.1/23.3 MB 1.6 MB/s eta 0:00:11\n",
      "     ---------- ----------------------------- 6.2/23.3 MB 1.6 MB/s eta 0:00:11\n",
      "     ---------- ----------------------------- 6.2/23.3 MB 1.6 MB/s eta 0:00:11\n",
      "     ---------- ----------------------------- 6.3/23.3 MB 1.6 MB/s eta 0:00:11\n",
      "     ----------- ---------------------------- 6.4/23.3 MB 1.6 MB/s eta 0:00:11\n",
      "     ----------- ---------------------------- 6.5/23.3 MB 1.6 MB/s eta 0:00:11\n",
      "     ----------- ---------------------------- 6.6/23.3 MB 1.6 MB/s eta 0:00:11\n",
      "     ----------- ---------------------------- 6.6/23.3 MB 1.6 MB/s eta 0:00:11\n",
      "     ----------- ---------------------------- 6.7/23.3 MB 1.6 MB/s eta 0:00:11\n",
      "     ----------- ---------------------------- 6.8/23.3 MB 1.6 MB/s eta 0:00:11\n",
      "     ----------- ---------------------------- 6.9/23.3 MB 1.6 MB/s eta 0:00:11\n",
      "     ----------- ---------------------------- 7.0/23.3 MB 1.6 MB/s eta 0:00:11\n",
      "     ------------ --------------------------- 7.1/23.3 MB 1.6 MB/s eta 0:00:10\n",
      "     ------------ --------------------------- 7.1/23.3 MB 1.6 MB/s eta 0:00:10\n",
      "     ------------ --------------------------- 7.2/23.3 MB 1.6 MB/s eta 0:00:10\n",
      "     ------------ --------------------------- 7.3/23.3 MB 1.6 MB/s eta 0:00:10\n",
      "     ------------ --------------------------- 7.4/23.3 MB 1.6 MB/s eta 0:00:10\n",
      "     ------------ --------------------------- 7.5/23.3 MB 1.6 MB/s eta 0:00:10\n",
      "     ------------ --------------------------- 7.5/23.3 MB 1.6 MB/s eta 0:00:10\n",
      "     ------------- -------------------------- 7.6/23.3 MB 1.6 MB/s eta 0:00:10\n",
      "     ------------- -------------------------- 7.7/23.3 MB 1.6 MB/s eta 0:00:10\n",
      "     ------------- -------------------------- 7.8/23.3 MB 1.6 MB/s eta 0:00:10\n",
      "     ------------- -------------------------- 7.9/23.3 MB 1.6 MB/s eta 0:00:10\n",
      "     ------------- -------------------------- 8.0/23.3 MB 1.6 MB/s eta 0:00:10\n",
      "     ------------- -------------------------- 8.0/23.3 MB 1.6 MB/s eta 0:00:10\n",
      "     ------------- -------------------------- 8.1/23.3 MB 1.6 MB/s eta 0:00:10\n",
      "     -------------- ------------------------- 8.2/23.3 MB 1.6 MB/s eta 0:00:10\n",
      "     -------------- ------------------------- 8.3/23.3 MB 1.6 MB/s eta 0:00:10\n",
      "     -------------- ------------------------- 8.4/23.3 MB 1.6 MB/s eta 0:00:10\n",
      "     -------------- ------------------------- 8.4/23.3 MB 1.6 MB/s eta 0:00:09\n",
      "     -------------- ------------------------- 8.5/23.3 MB 1.6 MB/s eta 0:00:09\n",
      "     -------------- ------------------------- 8.6/23.3 MB 1.6 MB/s eta 0:00:09\n",
      "     -------------- ------------------------- 8.7/23.3 MB 1.6 MB/s eta 0:00:09\n",
      "     --------------- ------------------------ 8.8/23.3 MB 1.6 MB/s eta 0:00:09\n",
      "     --------------- ------------------------ 8.9/23.3 MB 1.7 MB/s eta 0:00:09\n",
      "     --------------- ------------------------ 8.9/23.3 MB 1.6 MB/s eta 0:00:09\n",
      "     --------------- ------------------------ 9.0/23.3 MB 1.7 MB/s eta 0:00:09\n",
      "     --------------- ------------------------ 9.1/23.3 MB 1.7 MB/s eta 0:00:09\n",
      "     --------------- ------------------------ 9.2/23.3 MB 1.7 MB/s eta 0:00:09\n",
      "     --------------- ------------------------ 9.3/23.3 MB 1.7 MB/s eta 0:00:09\n",
      "     ---------------- ----------------------- 9.3/23.3 MB 1.7 MB/s eta 0:00:09\n",
      "     ---------------- ----------------------- 9.4/23.3 MB 1.7 MB/s eta 0:00:09\n",
      "     ---------------- ----------------------- 9.5/23.3 MB 1.7 MB/s eta 0:00:09\n",
      "     ---------------- ----------------------- 9.6/23.3 MB 1.7 MB/s eta 0:00:09\n",
      "     ---------------- ----------------------- 9.6/23.3 MB 1.7 MB/s eta 0:00:09\n",
      "     ---------------- ----------------------- 9.8/23.3 MB 1.7 MB/s eta 0:00:09\n",
      "     ---------------- ----------------------- 9.9/23.3 MB 1.7 MB/s eta 0:00:09\n",
      "     ----------------- ---------------------- 10.0/23.3 MB 1.7 MB/s eta 0:00:09\n",
      "     ----------------- ---------------------- 10.0/23.3 MB 1.7 MB/s eta 0:00:08\n",
      "     ----------------- ---------------------- 10.1/23.3 MB 1.7 MB/s eta 0:00:08\n",
      "     ----------------- ---------------------- 10.2/23.3 MB 1.7 MB/s eta 0:00:08\n",
      "     ----------------- ---------------------- 10.3/23.3 MB 1.7 MB/s eta 0:00:08\n",
      "     ----------------- ---------------------- 10.4/23.3 MB 1.7 MB/s eta 0:00:08\n",
      "     ----------------- ---------------------- 10.4/23.3 MB 1.7 MB/s eta 0:00:08\n",
      "     ------------------ --------------------- 10.5/23.3 MB 1.8 MB/s eta 0:00:08\n",
      "     ------------------ --------------------- 10.6/23.3 MB 1.8 MB/s eta 0:00:08\n",
      "     ------------------ --------------------- 10.7/23.3 MB 1.8 MB/s eta 0:00:08\n",
      "     ------------------ --------------------- 10.8/23.3 MB 1.8 MB/s eta 0:00:08\n",
      "     ------------------ --------------------- 10.9/23.3 MB 1.7 MB/s eta 0:00:08\n",
      "     ------------------ --------------------- 10.9/23.3 MB 1.7 MB/s eta 0:00:08\n",
      "     ------------------ --------------------- 11.0/23.3 MB 1.7 MB/s eta 0:00:08\n",
      "     ------------------- -------------------- 11.1/23.3 MB 1.7 MB/s eta 0:00:08\n",
      "     ------------------- -------------------- 11.2/23.3 MB 1.7 MB/s eta 0:00:07\n",
      "     ------------------- -------------------- 11.2/23.3 MB 1.7 MB/s eta 0:00:07\n",
      "     ------------------- -------------------- 11.3/23.3 MB 1.7 MB/s eta 0:00:07\n",
      "     ------------------- -------------------- 11.4/23.3 MB 1.7 MB/s eta 0:00:07\n",
      "     ------------------- -------------------- 11.5/23.3 MB 1.7 MB/s eta 0:00:07\n",
      "     ------------------- -------------------- 11.6/23.3 MB 1.7 MB/s eta 0:00:07\n",
      "     -------------------- ------------------- 11.7/23.3 MB 1.7 MB/s eta 0:00:07\n",
      "     -------------------- ------------------- 11.7/23.3 MB 1.9 MB/s eta 0:00:06\n",
      "     -------------------- ------------------- 11.8/23.3 MB 1.9 MB/s eta 0:00:06\n",
      "     -------------------- ------------------- 11.9/23.3 MB 1.9 MB/s eta 0:00:06\n",
      "     -------------------- ------------------- 12.0/23.3 MB 1.9 MB/s eta 0:00:06\n",
      "     -------------------- ------------------- 12.1/23.3 MB 1.9 MB/s eta 0:00:06\n",
      "     -------------------- ------------------- 12.1/23.3 MB 1.9 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 12.2/23.3 MB 1.9 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 12.3/23.3 MB 1.9 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 12.4/23.3 MB 1.9 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 12.5/23.3 MB 1.9 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 12.6/23.3 MB 1.9 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 12.6/23.3 MB 1.8 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 12.7/23.3 MB 1.8 MB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 12.8/23.3 MB 1.8 MB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 12.9/23.3 MB 1.8 MB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 13.0/23.3 MB 1.8 MB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 13.0/23.3 MB 1.8 MB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 13.1/23.3 MB 1.8 MB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 13.2/23.3 MB 1.8 MB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 13.3/23.3 MB 1.8 MB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 13.4/23.3 MB 1.8 MB/s eta 0:00:06\n",
      "     ----------------------- ---------------- 13.4/23.3 MB 1.7 MB/s eta 0:00:06\n",
      "     ----------------------- ---------------- 13.5/23.3 MB 1.7 MB/s eta 0:00:06\n",
      "     ----------------------- ---------------- 13.6/23.3 MB 1.7 MB/s eta 0:00:06\n",
      "     ----------------------- ---------------- 13.7/23.3 MB 1.7 MB/s eta 0:00:06\n",
      "     ----------------------- ---------------- 13.8/23.3 MB 1.7 MB/s eta 0:00:06\n",
      "     ----------------------- ---------------- 13.8/23.3 MB 1.8 MB/s eta 0:00:06\n",
      "     ----------------------- ---------------- 13.9/23.3 MB 1.8 MB/s eta 0:00:06\n",
      "     ------------------------ --------------- 14.0/23.3 MB 1.8 MB/s eta 0:00:06\n",
      "     ------------------------ --------------- 14.1/23.3 MB 1.8 MB/s eta 0:00:06\n",
      "     ------------------------ --------------- 14.2/23.3 MB 1.8 MB/s eta 0:00:06\n",
      "     ------------------------ --------------- 14.2/23.3 MB 1.8 MB/s eta 0:00:06\n",
      "     ------------------------ --------------- 14.3/23.3 MB 1.7 MB/s eta 0:00:06\n",
      "     ------------------------ --------------- 14.4/23.3 MB 1.7 MB/s eta 0:00:06\n",
      "     ------------------------ --------------- 14.5/23.3 MB 1.7 MB/s eta 0:00:06\n",
      "     ------------------------- -------------- 14.6/23.3 MB 1.7 MB/s eta 0:00:06\n",
      "     ------------------------- -------------- 14.6/23.3 MB 1.7 MB/s eta 0:00:05\n",
      "     ------------------------- -------------- 14.7/23.3 MB 1.7 MB/s eta 0:00:05\n",
      "     ------------------------- -------------- 14.8/23.3 MB 1.7 MB/s eta 0:00:05\n",
      "     ------------------------- -------------- 14.9/23.3 MB 1.7 MB/s eta 0:00:05\n",
      "     ------------------------- -------------- 15.0/23.3 MB 1.7 MB/s eta 0:00:05\n",
      "     ------------------------- -------------- 15.1/23.3 MB 1.7 MB/s eta 0:00:05\n",
      "     -------------------------- ------------- 15.1/23.3 MB 1.7 MB/s eta 0:00:05\n",
      "     -------------------------- ------------- 15.2/23.3 MB 1.7 MB/s eta 0:00:05\n",
      "     -------------------------- ------------- 15.3/23.3 MB 1.7 MB/s eta 0:00:05\n",
      "     -------------------------- ------------- 15.4/23.3 MB 1.7 MB/s eta 0:00:05\n",
      "     -------------------------- ------------- 15.5/23.3 MB 1.7 MB/s eta 0:00:05\n",
      "     -------------------------- ------------- 15.6/23.3 MB 1.7 MB/s eta 0:00:05\n",
      "     -------------------------- ------------- 15.6/23.3 MB 1.7 MB/s eta 0:00:05\n",
      "     --------------------------- ------------ 15.7/23.3 MB 1.7 MB/s eta 0:00:05\n",
      "     --------------------------- ------------ 15.8/23.3 MB 1.7 MB/s eta 0:00:05\n",
      "     --------------------------- ------------ 15.9/23.3 MB 1.7 MB/s eta 0:00:05\n",
      "     --------------------------- ------------ 16.0/23.3 MB 1.7 MB/s eta 0:00:05\n",
      "     --------------------------- ------------ 16.0/23.3 MB 1.7 MB/s eta 0:00:05\n",
      "     --------------------------- ------------ 16.1/23.3 MB 1.7 MB/s eta 0:00:05\n",
      "     --------------------------- ------------ 16.2/23.3 MB 1.7 MB/s eta 0:00:05\n",
      "     --------------------------- ------------ 16.3/23.3 MB 1.7 MB/s eta 0:00:05\n",
      "     ---------------------------- ----------- 16.4/23.3 MB 1.7 MB/s eta 0:00:04\n",
      "     ---------------------------- ----------- 16.4/23.3 MB 1.7 MB/s eta 0:00:04\n",
      "     ---------------------------- ----------- 16.5/23.3 MB 1.7 MB/s eta 0:00:04\n",
      "     ---------------------------- ----------- 16.6/23.3 MB 1.7 MB/s eta 0:00:04\n",
      "     ---------------------------- ----------- 16.7/23.3 MB 1.7 MB/s eta 0:00:04\n",
      "     ---------------------------- ----------- 16.8/23.3 MB 1.7 MB/s eta 0:00:04\n",
      "     ---------------------------- ----------- 16.8/23.3 MB 1.7 MB/s eta 0:00:04\n",
      "     ----------------------------- ---------- 16.9/23.3 MB 1.7 MB/s eta 0:00:04\n",
      "     ----------------------------- ---------- 17.0/23.3 MB 1.7 MB/s eta 0:00:04\n",
      "     ----------------------------- ---------- 17.1/23.3 MB 1.7 MB/s eta 0:00:04\n",
      "     ----------------------------- ---------- 17.2/23.3 MB 1.7 MB/s eta 0:00:04\n",
      "     ----------------------------- ---------- 17.3/23.3 MB 1.7 MB/s eta 0:00:04\n",
      "     ----------------------------- ---------- 17.3/23.3 MB 1.7 MB/s eta 0:00:04\n",
      "     ----------------------------- ---------- 17.4/23.3 MB 1.7 MB/s eta 0:00:04\n",
      "     ------------------------------ --------- 17.5/23.3 MB 1.7 MB/s eta 0:00:04\n",
      "     ------------------------------ --------- 17.6/23.3 MB 1.7 MB/s eta 0:00:04\n",
      "     ------------------------------ --------- 17.7/23.3 MB 1.7 MB/s eta 0:00:04\n",
      "     ------------------------------ --------- 17.7/23.3 MB 1.7 MB/s eta 0:00:04\n",
      "     ------------------------------ --------- 17.8/23.3 MB 1.7 MB/s eta 0:00:04\n",
      "     ------------------------------ --------- 17.9/23.3 MB 1.7 MB/s eta 0:00:04\n",
      "     ------------------------------ --------- 18.0/23.3 MB 1.7 MB/s eta 0:00:04\n",
      "     ------------------------------- -------- 18.1/23.3 MB 1.7 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 18.2/23.3 MB 1.7 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 18.2/23.3 MB 1.7 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 18.3/23.3 MB 1.7 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 18.4/23.3 MB 1.7 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 18.5/23.3 MB 1.7 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 18.6/23.3 MB 1.7 MB/s eta 0:00:03\n",
      "     -------------------------------- ------- 18.6/23.3 MB 1.7 MB/s eta 0:00:03\n",
      "     -------------------------------- ------- 18.7/23.3 MB 1.7 MB/s eta 0:00:03\n",
      "     -------------------------------- ------- 18.8/23.3 MB 1.7 MB/s eta 0:00:03\n",
      "     -------------------------------- ------- 18.9/23.3 MB 1.7 MB/s eta 0:00:03\n",
      "     -------------------------------- ------- 19.0/23.3 MB 1.7 MB/s eta 0:00:03\n",
      "     -------------------------------- ------- 19.0/23.3 MB 1.7 MB/s eta 0:00:03\n",
      "     -------------------------------- ------- 19.1/23.3 MB 1.7 MB/s eta 0:00:03\n",
      "     -------------------------------- ------- 19.2/23.3 MB 1.7 MB/s eta 0:00:03\n",
      "     --------------------------------- ------ 19.3/23.3 MB 1.7 MB/s eta 0:00:03\n",
      "     --------------------------------- ------ 19.4/23.3 MB 1.7 MB/s eta 0:00:03\n",
      "     --------------------------------- ------ 19.4/23.3 MB 1.7 MB/s eta 0:00:03\n",
      "     --------------------------------- ------ 19.5/23.3 MB 1.7 MB/s eta 0:00:03\n",
      "     --------------------------------- ------ 19.6/23.3 MB 1.7 MB/s eta 0:00:03\n",
      "     --------------------------------- ------ 19.7/23.3 MB 1.7 MB/s eta 0:00:03\n",
      "     --------------------------------- ------ 19.8/23.3 MB 1.7 MB/s eta 0:00:03\n",
      "     ---------------------------------- ----- 19.9/23.3 MB 1.7 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 19.9/23.3 MB 1.7 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 20.0/23.3 MB 1.7 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 20.1/23.3 MB 1.7 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 20.2/23.3 MB 1.7 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 20.3/23.3 MB 1.7 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 20.3/23.3 MB 1.7 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 20.4/23.3 MB 1.7 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 20.5/23.3 MB 1.7 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 20.6/23.3 MB 1.7 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 20.7/23.3 MB 1.7 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 20.7/23.3 MB 1.7 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 20.8/23.3 MB 1.7 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 20.9/23.3 MB 1.7 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 21.0/23.3 MB 1.7 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 21.1/23.3 MB 1.7 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 21.1/23.3 MB 1.7 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 21.2/23.3 MB 1.7 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 21.3/23.3 MB 1.7 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 21.4/23.3 MB 1.7 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 21.5/23.3 MB 1.7 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 21.6/23.3 MB 1.7 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 21.6/23.3 MB 1.7 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 21.7/23.3 MB 1.7 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 21.8/23.3 MB 1.7 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 21.9/23.3 MB 1.7 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 22.0/23.3 MB 1.7 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 22.0/23.3 MB 1.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 22.1/23.3 MB 1.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 22.2/23.3 MB 1.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 22.3/23.3 MB 1.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 22.4/23.3 MB 1.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 22.4/23.3 MB 1.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 22.5/23.3 MB 1.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 22.6/23.3 MB 1.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 22.7/23.3 MB 1.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  22.8/23.3 MB 1.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  22.8/23.3 MB 1.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  22.9/23.3 MB 1.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  22.9/23.3 MB 1.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  22.9/23.3 MB 1.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  22.9/23.3 MB 1.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  23.0/23.3 MB 1.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  23.3/23.3 MB 1.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  23.3/23.3 MB 1.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  23.3/23.3 MB 1.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  23.3/23.3 MB 1.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 23.3/23.3 MB 1.7 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gensim) (1.26.1)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gensim) (1.11.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gensim) (6.4.0)\n",
      "Building wheels for collected packages: gensim\n",
      "  Building wheel for gensim (pyproject.toml): started\n",
      "  Building wheel for gensim (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for gensim: filename=gensim-4.3.2-cp312-cp312-win_amd64.whl size=23939065 sha256=39ceee763f2e1c4ad345faedc5b21c46e7dd1a33ed491c6eb73ef7c2b39a8afb\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\50\\c0\\ac\\7bb08954bc59d390c848b480a3fc5eec68c14bc77bf334d624\n",
      "Successfully built gensim\n",
      "Installing collected packages: gensim\n",
      "Successfully installed gensim-4.3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.31.0)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2023.7.22)\n",
      "Requirement already satisfied: PyPDF2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "## Install all dependencies\n",
    "%pip install gensim\n",
    "# %pip install nltk\n",
    "# %pip install pandas\n",
    "# %pip install numpy\n",
    "%pip install requests\n",
    "%pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.1.2)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (1.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk\n",
    "%pip install pandas\n",
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "from numpy.linalg import norm\n",
    "#from termcolor import colored\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import PyPDF2\n",
    "import re\n",
    "#import plotly.graph_objects as go\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data science', 'information science', 'computer science', 'software project management', 'cybersecurity', 'data analysis', 'artificial intelligence', 'computer vision', 'computer software', 'systems analysis', 'programming', 'mathematics', 'web development', 'statistics', 'software development', 'nlp', 'software engineering', 'systems and network administration', 'network security', 'information systems', 'information technology', 'computer engineering', 'nlp engineering', 'computer programming', 'data engineering', 'ai engineering']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Read the JSONL file and extract labels\n",
    "majors_list = []\n",
    "\n",
    "with open('majors.jsonl', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line)\n",
    "        label_parts = data[\"label\"].split('|')\n",
    "        \n",
    "        # Extract the label after the second '|', replace hyphens with spaces\n",
    "        extracted_label = label_parts[2].replace('-', ' ')\n",
    "        \n",
    "        # Append the extracted label to the list\n",
    "        majors_list.append(extracted_label)\n",
    "\n",
    "# Print the resulting list\n",
    "majors_list = list(set(majors_list))\n",
    "print(majors_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mvc tools', 'spring', 'vue.js', 'data analysis', 'apache zeppelin', 'file uploads', 'random access', 'synthetic aperture radar', 'phpunit', 'image analysis api', 'neural coding', 'correctness', 'api tools', 'git', 'query optimization', 'confluence', 'metabase', 'information theory', 'faceted classification', 'hugo', 'classifier linguistics', 'semantic computing', 'jupyter notebook', 'analytics', 'genetic algorithm', 'abstract machine', 'segmentation', 'g suite', 'facial expression detection', 'backbone.js', 'critical mass software engineering', 'pattern recognition', 'gluon', 'data stores', 'error concealment', 'messenger platform', 'simulated annealing', 'virtualization platform', 'wireframing', 'utilities', 'brute force search', 'fragmentation computing', 'gatling', 'read write memory', 'latex', 'opengl', 'clicktale', 'survey widget', 'edit distance', 'semantics', 'augmented reality', 'content writing', 'dynamic loading', 'rocket', 'amazon ec2', 'biomedical engineering', 'collision', 'active database', 'real time data', 'amazon rds for postgresql', 'next.js', 'vuepress', 'aws cloudformation', 'process calculus', 'asana', 'telecommunications network', 'analog to digital converter', 'mobility model', 'time sharing', 'ruby', 'chatbot', 'docker for aws', 'natural language understanding', 'nuxt.js', 'flip flop', 'multi user', 'optimizely', 'tracking system', 'folksonomy', 'self hosted blogging / cms', 'apiary', 'user feedback as a service', 'patent classification', 'directed graph', 'nativescript', 'deadlock', 'caddy', 'sphinx', 'international trade', 'documentation', 'findability', 'performance metric', 'amazon sqs', 'semaphore', 'codenvy', 'abstract interpretation', 'composite index', 'data flow diagram', 'turing machine', 'mutual information', 'reliability computer networking', 'high availability', 'memcachier', 'netlify', 'semantic web stack', 'logistic regression', 'cepstrum', 'cataloging', 'mandrill', 'searchretrieve via url', 'frameworks full stack', 'advertising', 'curse of dimensionality', 'tableau', 'ecommerce', 'residual', 'google tag manager', 'gatsby', 'mongodb hosting', 'navigation system', 'kibana', 'application hosting', 'point to point', 'material design for bootstrap', 'formal language', 'time tracking', 'jest', 'sql database as a service', 'copy protection', 'superset', 'information seeking', 'cloudflare', 'web components', 'wireless', 'google app maker', 'encryption', 'postcss', 'bayesian inference', 'hhvm', 'heroku ci', 'microservices tools', 'virtual machine', 'forensic engineering', 'voice over ip', 'local search optimization', 'content delivery network', 'multicast', 'f', 'kanban tool', 'factorial experiment', 'network delay', 'fastly', 'motion analysis', 'containers as a service', 'devdocs', 'azure machine learning', 'ajax', 'rubocop', 'serverless', 'openresty', 'google cloud storage', 'javascript utilities libraries', 'microsoft bot framework', 'particle filter', 'email marketing', 'file format', 'time of arrival', 'heroku', 'secrets management', 'microdata html', 'network layer', 'yii', 'homogeneity statistics', 'machine learning', 'amazon cloudfront', 'eclipse', 'rackspace cloud servers', 'ionic', 'google compute engine', 'stripe', 'linear search', 'wavefront', 'typeorm', 'first order logic', 'debian', 'traffic engineering', 'web starter kit', 'smart card', 'swagger ui', 'julia', 'dns management', 'preactjs', 'bottom up model', 'engineering', 'specification', 'neural network', 'redash', 'activity recognition', 'time series', 'maxcdn', 'amazon kinesis', 'varnish', 'programming languages', 'knowledge extraction', 'domain knowledge', 'random projection', 'information management', 'semi supervised learning', 'tfidf', 'persistence computer science', 'amazon cognito', 'similarity measure', 'ansible', 'network topology', 'sql', 'communication in small groups', 'ground truth', 'apigee', 'compressed sensing', 'mobile station', 'wireless ad hoc network', 'jruby', 'logrocket', 'false positive rate', 'sonatype nexus', 'codeship', 'pandas', 'scala', 'docker cloud', 'microcomputer', 'gaussian process', 'haproxy', 'supervisory control', 'computer graphics', 'load management', 'raspberry pi', 'canonical model', 'mysql', 'reachability', 'industrial engineering', 'access method', 'material design', 'amazon cloudwatch', 'web development', 'latency engineering', 'f#', 'keycdn', 'apache cordova', 'opensuse', 'clubhouse', 'redux', 'clinicalkey', 'network security', 'temporal database', 'communication complexity', 'gitlab', 'tree automaton', 'meteor', 'salesforce sales cloud', 'aws lambda', 'js task runners', 'dash', 'dynamic data', 'gradient descent', 'api.ai', 'link relation', 'sliding window protocol', 'decision tree', 'google scholar and academic libraries', 'webflow', 'translation service', 'deductive database', 'kotlin', 'read only memory', 'drupal', 'javascript', 'front end package manager', 'sass', 'ava', 'automaton', 'bamboo', 'supercomputer', 'circleci', 'unified modeling language', 'electronic document', 'microprocessor', 'monitoring tools', 'deployment as a service', 'discriminative model', 'structural equation modeling', 'decidability', 'knowledge representation and reasoning', 'finagle', 'prometheus', 'text mining', 'commenting service', 'strips', 'datalog', 'digital signature', 'queues', 'dart', 'awx', 'aspect oriented programming', 'ethernet', 'ubiquitous computing', 'fault tolerance', 'clientserver model', 'document management system', 'multivariate statistics', 'asp.net', 'computer graphics images', 'multimedia', 'iterative reconstruction', 'gunicorn', 'breadth first search', 'spreadsheets online', 'word sense disambiguation', 'regular language', 'reverse engineering', 'figma', 'bag of words model', 'thresholding', 'named entity', 'highcharts js', 'information model', 'subject access', 'uppy', 'mercurial', 'computer data storage', 'xml', 'figure of merit', 'flat panel display', 'zend framework', 'amazon elasticsearch service', 'file storage', 'node networking', 'bibliometrics', 'localhost tools', 'redis hosting', 'php', 'google cloud sql', 'react', 'marine engineering', 'pushdown automaton', 'publishing', 'econometric model', 'response time', 'memcached', 'github pages', 'git tools', 'raml', 'codeigniter', 'apache spark', 'omniauth', 'multilevel model', '.net', 'react.js boilerplate', 'jquery mobile', 'static timing analysis', 'web document', 'matlab', 'rule induction', 'result set', 'azure functions', 'disjunctive normal form', 'round trip delay time', 'akamai', 'control engineering', 'object detection', 'data science tools', 'natural language processing', 'rollbar', 'shrinkage', 'codec', 'neovim', 'surge', 'ratchet', 'zoho crm', 'bayesian probability', 'azure', 'machine learning as a service', 'central processing unit', 'cross validation', 'impala', 'conditional random field', 'sonarqube', 'rails', 'errors in variables models', 'mobile prototyping', 'replication computing', 'index term', 'minio', 'jquery ui', 'functional testing', 'fuzzy logic', 'bulma', 'pattern recognition psychology', 'woopra', 'computer network', 'google cloud bigtable', 'knowledge retrieval', 'adobe xd', 'amazon api gateway', 'background processing', 'coveralls', 'active shape model', 'code climate', 'javascript framework components', 'aws opsworks', 'spring cloud', 'scalability', 'mining engineering', 'typeform', 'power control', 'authentication', 'canonical correlation', 'feature vector', 'framer', 'ibm db2', 'optical transfer function', 'gitlab ci', 'sauce labs', 'actuarial science', 'scale space', 'gulp.js', 'bitcoin', 'apache maven', 'dimensionality reduction', 'beta testing & mobile app distribution', 'invision', 'remote procedure call', 'code generation', 'deco', 'payment services', 'topic maps', 'telegram', 'clojurescript', 'google drive', 'dynamic testing', 'actuator', 'mixture model', 'critical path method', 'etcd', 'financial system', 'next generation network', 'r', 'pingdom', 'data pre processing', 'expander graph', 'linear model', 'istio', 'aws codecommit', 'medical imaging', 'react hot loader', 'binary search tree', 'google cloud vision api', 'object document mapper', 'gitkraken', 'pytorch', 'appveyor', 'relative record data set', 'realtime analytics', 'self organization', 'shortest path problem', 'clustring', 'google cloud container builder', 'aws iam', 'plotly', 'logstash', 'shippable', 'programmable logic device', 'framework7', 'big data tools', 'amazon kinesis firehose', 'headless browsers', 'kalman filter', 'qt', 'hubspot', 'mathematical logic', 'arboriculture', 'sourcetree', 'frontend', 'triangulation social science', 'multispectral image', 'speech recognition', 'regular expression', 'graphic design', 'amazon ec2 container service', 'kong', 'key lock', 'description logic', 'hogan.js', 'distributed system', 'cobol', 'testflight', 'unity', 'field of view', 'tools for text editors', 'boolean expression', 'robustness computer science', 'distributed computing environment', 'word error rate', 'overlay network', 'mobile push messaging', 'hotjar', 'django', 'artificial neural network', 'pushwoosh', 'visual studio team services', 'vue', 'apache kafka', 'telephony', 'query expansion', 'kullbackleibler divergence', 'redis cloud', 'spread spectrum', 'mobile continuous integration', 'datadog', 'js build tools', 'mobile testing frameworks', 'linode', 'inference', 'markup language', 'wavelet', 'notepad', 'cluster management', 'biometrics', 'rule based system', 'recurly', 'formal verification', 'telegram bot api', 'change detection', 'apache mesos', '1password', 'image registration', 'jsdoc', 'visual programming language', 'codacy', 'fullstory', 'cloud ide', 'adaptive system', 'rails api', 'prognostics', 'line of sight', 'template matching', 'locust', 'confirmatory factor analysis', 'buffer overflow', 'fluentd', 'natural language', 'motion compensation', 'npm', 'mongoid', 'noisy data', 'dnsimple', 'mongodb stitch', 'grails', 'resque', 'linear discriminant analysis', 'knex.js', 'training model', 'region of interest', 'aws elastic beanstalk', 'filestack', 'coffeescript', 'arch linux', 'traffic model', 'kendo ui', 'routing protocol', 'satisfiability', 'feathersjs', 'phpstorm', 'apache storm', 'expressjs', 'noise measurement', 'computer engineering', 'clion', 'local area network', 'generalization error', 'document retrieval', 'morphology linguistics', 'linear programming', 'sequel pro', 'computer vision', 'stylelint', 'mobile error monitoring', 'modal logic', 'particle swarm optimization', 'information retrieval query language', 'point location', 'reactiveui', 'computational geometry', 'business tools', 'd3.js', 'built in self test', 'google maps', 'sma', 'prosthesis', 'geotagging', 'multidimensional scaling', 'analysis of covariance', 'sqlite', 'virtual machine management', 'concept learning', 'content management', 'coding social sciences', 'ir evaluation', 'missing data', 'react navigation', 'scaleway', 'apache hbase', 'mina', 'compiler', 'corner detection', 'outlier', 'terraform', 'logic synthesis', 'microcontroller', 'clojure', 'clicky', 'intelligent agent', 'nats', 'visual basic', 'postmark', 'google kubernetes engine', 'google cloud dataflow', 'redundancy engineering', 'eureka', 'dynamic source routing', 'business', 'motion estimation', 'operations research', 'mobile interaction design tools', 'polymer', 'sencha touch', 'association rule learning', 'cross platform mobile development', 'fusion', 'human visual system model', 'internet of things hardware', 'deep learning', 'civil engineering', 'wagtail', 'zepto', 'website monitoring', 'predictive coding', 'divide and conquer algorithms', 'data stream mining', 'browsersync', 'search as a service', 'boosting machine learning', 'motion detection', 'point spread function', 'multivariate analysis', 'lexico', 'engineering ethics', 'microframeworks', 'decision support system', 'stackdriver', 'phoenix framework', 'protractor', 'aws codedeploy', 'objective c', 'code quality', 'p system', 'emacs', 'heroku postgres', 'data science', 'first class', 'video quality', 'external data representation', 'leaflet', 'amazon elasticache', 'scaffold', 'ember.js', 'mattermost', 'database transaction', 'adaboost', 'software agent', 'legal information retrieval', 'aws codebuild', 'plagiarism detection', 'front and back ends', 'aurelia', 'electrical engineering', 'responsive design', 'tools for github', 'uptime robot', 'puppeteer', 'node.js', 'microframeworks backend', 'error detection and correction', 'wordnet', 'lottie', 'lxd', 'wireless sensor network', 'code collaboration and version control', 'apache subversion', 'zeplin', 'database design', 'adobe phonegap', 'random indexing', 'histogram', 'dokku', 'piwik', 'mongodb', 'graph databases', 'clone java method', 'application utilities', 'graphite', 'rabbitmq', 'performance prediction', 'message passing', 'sqlalchemy', 'time to market', 'mobile development', 'operator computer programming', 'softlayer', 'tensorflow', 'csharp', 'link analysis', 'concurrency control', 'firebase crashlytics', 'distributed algorithm', 'concurrency frameworks', 'human computer interaction', 'testing', 'display device', 'top down model', 'document processing', 'project management', 'web crawler', 'liquibase', 'virtual machine platforms / containers', 'emotion recognition', 'consistency model', 'emulator', 'data extraction', 'web service automation', 'information overload', 'arbol', 'k d tree', 'analytics integrator', 'domain registration', 'hierarchical database model', 'redux thunk', 'object relational mapper', 'incapsula', 'source separation', 'level set', 'systems management', 'vault', 'crazy egg', 'google bigquery', 'cassandra', 'eye tracking', 'digital signal processing', 'amazon sns', 'text retrieval conference', 'gsm', 'linear logic', 'field programmable gate array', 'static site generators', 'telecommunications', 'optical recording', 'heatmap analytics', 'server', 'phantomjs', 'java', 'loggly', 'variables', 'amplitude', 'parsing', 'vuex', 'phalcon', 'computer program', 'continuous integration', 'database', 'feature selection', 'parallel computing', 'sorting', 'chemical engineering', 'cloudinary', 'location based service', 'clever cloud', 'computation', 'wix', 'codebook', 'password management', 'intelligent document processing', 'real time computing', 'multi core processor', 'solr', 'cloud9 ide', 'digitalocean', 'browserstack', 'travelling salesman problem', 'scrutinizer', 'hypercube', 'fedora', 'technological change', 'data processing', 'curve fitting', 'go', 'visual inspection', 'sentiment analysis', 'nuclear engineering', 'xcode', 'floating point', 'ant design', 'discrete system', 'spreadsheets as a backend', 'cpp', 'jetty', 'code coverage', 'database tools', 'enterprise system', 'generalized linear model', 'combinatorial optimization', 'data integration', 'naive bayes classifier', 'transparency graphic', 'data validation', 'multidimensional analysis', 'javascript testing framework', 'iframely', 'rdf', 'scripting language', 'communications sdk', 'puma', 'devops', 'key exchange', 'charting libraries', 'matched filter', 'pico 8', 'remote control', 'independent set', 'semantic html', 'browserify', 'business administration', 'hash function', 'structured text', 'socket.io', 'access network', 'bot', 'search engine', 'mustache', 'integer programming', 'dynamic time warping', 'mailchimp', 'unified medical language system', 'mongoose', 'web app builders', 'algolia', 'portainer', 'optical disc', 'automatic taxonomy induction', 'data structure', 'automotive engineering', 'godaddy', 'ifttt', 'firebase', 'google cloud functions', 'chartbeat', 'discrete logarithm', 'atom', 'runscope', 'correlation coefficient', 'control theory', 'customer relationship management', 'terminal', 'diagram', 'prestashop', 'program optimization', 'base station', 'passenger', 'deontic logic', 'big data', 'fossa', 'chrome', 'application programming interface', 'unicorn', 'funnel analysis analytics', 'mobile agent', 'octopus deploy', 'adobe photoshop', 'path analysis statistics', 'google cloud pubsub', 'heroku redis', 'duplicate content', 'statuscake', 'media access control', 'kanban for github issues', 'environmental engineering', 'flask', 'systems engineering', 'logic in computer science', 'cdnjs', 'data compression', 'independent component analysis', 'file system', 'decomposition method constraint satisfaction', 'chemometrics', 'cloud content management system', 'domain model', 'email testing', 'feature extraction', 'numpy', 'finance', 'biological database', 'security', 'predictive value', 'collaboration', 'commerce', 'smart information retrieval system', 'mesh networking', 'computational model', 'cryptography', 'non volatile memory', 'thread computing', 'windows', 'geometric modeling', 'metis', 'frequency domain', 'onsen ui', 'travis ci', 'markov chain', 'throughput', 'computational complexity theory', 'mailgun', 'data classification', 'look ahead', 'dempstershafer theory', 'azure cosmos db', 'stream processing', 'amazon rds for aurora', 'cross platform desktop development', 'django rest framework', 'queueing theory', 'computer hardware', 'component', 'continuum design consultancy', 'rubymine', 'bourbon', 'intellij idea', 'knowledge acquisition', 'docker compose', 'process management', 'data center', 'internetworking', 'uglifyjs', 'economic policy', 'mvc', 'computability theory', 'convergence routing', 'mean shift', 'type inference', 'fabric by twitter', 'frequency analysis', 'system on a chip', 'distributed object', 'woocommerce', 'onesignal', 'automated reasoning', 'pug', 'distributed file system', 'relational database', 'aws', 'nosql', 'dyn', 'source code management desktop apps', 'computational science', 'semantic matching', 'visual cortex', 'mobile telephony', 'json server', 'in memory databases', 'laravel', 'electronic data interchange', 'intercom', 'secure multi party computation', 'jira', 'multi agent system', 'latent semantic indexing', 'airtable', 'recursion', 'user interface', 'ngrok', 'sequential pattern mining', 'crowdsourcing', 'flyway', 'photogrammetry', 'aws direct connect', 'quality assurance', 'buildkite', 'internet privacy', 'containers', 'pixel art', 'cloud foundry', 'web and video conferencing', 'exploratory data analysis', 'kubernetes', 'shields.io', 'flutter', 'jquery', 'forecasting', 'javascript ui libraries', 'drone.io', 'incremental learning', 'speech processing', 'apache zookeeper', 'middleman', 'wordpress', 'android', 'amazon emr', 'dropwizard', 'statistical classification', 'hidden markov model', 'html', 'stylus', 'lookup table', 'knowledge management', 'linear prediction', 'transition system', 'exact algorithm', 'stitch', 'text box', 'google cloud memorystore', 'aeronautics', 'wiener filter', 'akka', 'amazon s3', 'data stream', 'amazon redshift', 'packer', 'capistrano', 'reliability engineering', 'octodns', 'adobe illustrator', 'sonar', 'secret sharing', 'gaussian noise', 'table information', 'static web hosting', 'game development', 'intelligent network', 'voice and sms', 'nim', 'network simulation', 'rule of thumb', 'presentation semantics', 'mesosphere', 'bootswatch', 'mvvmcross', 'knowledge based systems', 'design for testing', 'mobile robot', 'vector space model', 'cakephp', 'cross correlation', 'signalr', 'recommender system', 'prisma', 'biochemical engineering', 'mapping apis', 'cloud functions for firebase', 'rancher', 'real time communication', 'influxdb', 'azure storage', 'audio signal', 'information filtering system', 'integrated development environment tools', 'business dashboards', 'discrete cosine transform', 'speckle pattern', 'data acquisition', 'gitlab pages', 'computer architecture', 'brain mapping', 'back office', 'dijkstras algorithm', 'react native', 'bower', 'nitrous.io', 'higher order statistics', 'flash memory', 'social media tools', 'process engineering', 'multisearch', 'title search', 'aerial photography', 'platform as a service', 'abstract data type', 'computer multitasking', 'finite state machine', 'open data', 'theoretical computer science', 'source document', 'google app engine', 'data retrieval', 'document layout analysis', 'junit', 'amazon rds', 'javascript mvc frameworks', 'concourse', 'uncertain data', 'document signature', 'paypal', 'postgresql', 'principal component analysis', 'arborist', 'classical logic', 'sequential logic', 'lambdatest', 'debugging', 'rethinkdb', 'hipchat', 'information discovery', 'interconnection', 'programming & code analytics', 'openlayers', 'pulp and paper industry', 'hetzner online ag', 'ibm api management', 'supervised learning', 'pouchdb', 'wordplate', 'medical literature retrieval', 'digital radio', 'aws codepipeline', 'euclidean distance', 'python', 'library science', 'search algorithm', 'eslint', 'quantifier elimination', 'unsupervised learning', 'art  architecture thesaurus', 'react storybook', 'codecov', 'network congestion', 'apache ant', 'lxc', 'scientometrics', 'css pre processors & extensions', 'lambda calculus', 'conductor', 'zendesk', 'automated theorem proving', 'postgresql as a service', 'go.cd', 'nsq', 'viterbi algorithm', 'data manipulation language', 'ml kit', 'bootstrap', 'github api', 'beanstalk', 'complex data type', 'reinforcement learning', 'latent dirichlet allocation', 'prolog', 'mechanical engineering', 'mixed model', 'open source cloud', 'flow control data', 'spatial frequency', 'netty', 'business intelligence', 'image segmentation', 'couchbase', 'robot', 'amazon vpc', 'cluster analysis', 'network model', 'traefik', 'formal methods', 'lastpass', 'critical section', 'testing frameworks', 'digital subscriber line', 'engagement lifecycle marketing', 'deployment', 'formal concept analysis', 'moving average', 'workflow manager', 'language model', 'backend', 'zenefits', 'selenium', 'marionette.js', 'ffmpeg', 'cost database', 'aerospace engineering', 'new relic', 'coreos', 'electron', 'automatic summarization', 'link layer', 'virtualbox', 'log management', 'data mining', 'natural deduction', 'case based reasoning', 'program synthesis', 'intrusion detection system', 'gerrit code review', 'materialize', 'shopify', 'am php', 'seasonality', 'management science', 'petroleum engineering', 'contextual query language', 'graphical model', 'aws elastic load balancing elb', 'monero', 'layout engine', 'logic programming', 'image processing and management', 'lets encrypt', 'es6', 'image fusion', 'hybrid system', 'sketch', 'qunit', 'ipfs', 'data as a service', 'mobx', 'beta by crashlytics', 'jenkins', 'text processing', 'formal specification', 'swift', 'stars', 'phaser', 'search engine indexing', 'wireless network', 'fortran', 'cellular network', 'jasmine', 'slim', 'symfony', 'grape.js', 'virtual organization', 'momentjs', 'data logger', 'aerospike', 'erasure code', 'pattern matching', 'real time operating system', 'network performance', 'babel', 'build test deploy', 'immutable.js', 'enzyme', 'linked data', 'standard ml', 'docker swarm', 'adaptive routing', 'symmetric multiprocessor', 'statistical model', 'decision rule', 'static random access memory', 'question answering', 'web mining', 'spring boot', 'sendwithus', 'groovy', 'mixpanel', 'cloud access management', 'macos', 'celery', 'distributed computing', 'architectural engineering', 'complex system', 'game engine', 'grpc', 'object model', 'tabu search', 'frameworks', 'computer file', 'spacemacs', 'homebridge', 'haml', 'knowledge modeling', 'access control', 'quantum algorithm', 'bazel', 'mutual exclusion', 'network planning and design', 'swiftype', 'squarespace', 'scheduling computing', 'performance monitoring', 'codekit', 'amazon ses', 'computer programming', 'named entity recognition', 'bash', 'dcos', 'reference frame', 'quantum computing', 'sparse approximation', 'mailjet', 'mobile radio', 'boot2docker', 'artificial intelligence', 'data quality', 'program design language', 'modelling', 'deterministic automaton', 'high level programming language', 'agile project management', 'angular', 'storybook', 'twilio', 'communications protocol', 'hazelcast', 'controlled vocabulary', 'data file', 'trend analysis', 'specification language', 'cross platform mobile tools', 'pulse signal processing', 'real time data processing', 'pwa', 'trecvid', 'memory management', 'system integration', 'multimodal search', 'network interface', 'jitter', 'cloud firestore', 'shell', 'parcel', 'telecommunications service', 'marketing', 'docker machine', 'karhunenlove theorem', 'skeleton', 'garbage collection', 'c3.js', 'shift register', 'software defined radio', 'flux', 'algorithm', 'general analytics', 'docker', 'mobile analytics', 'cranfield experiments', 'synchronization', 'document collaboration', 'virtual memory', 'software', 'transport engineering', 'oracle', 'asynchronous transfer mode', 'custom analytics', 'knapsack problem', 'logic gate', 'constant false alarm rate', 'sails.js', 'communications system', 'proximity search', 'container tools', 'secure communication', 'shape analysis digital geometry', 'rspec', 'wimax', 'video editing', 'ethereum', 'algorithm design', 'communications', 'petri net', 'redis', 'readme.io', 'control reconfiguration', 'quality of service', 'inter process communication', 'motion planning', 'random effects model', 'infrastructure build tools', 'nexmo', 'blind signal separation', 'css', 'netbeans ide', 'system testing', 'lua', 'data access', 'linux', 'weebly', 'segment', 'program analysis', 'rest api', 'computability', 'knowledge base', 'chatops', 'polymorphism', 'xamarin', 'browser testing', 'modular design', 'azure websites', 'automatic programming', 'core network', 'elm', 'handlebars.js', 'seesaw', 'concurrent computing', 'denial of service attack', 'active networking', 'comprehension', 'open source service discovery', 'semantic ui react', 'type theory', 'ensemble learning', 'interactive mockups', 'presto', 'version control system', 'data exchange', 'wavelength division multiplexing', 'fabric', 'information integration', 'customer support chat', 'relay', 'heap', 'keras', 'consul', 'batch processing', 'video tracking', 'marathon', 'data consistency', 'instrumental variable', 'common object request broker architecture', 'handover', 'redux saga', 'time domain', 'stereopsis', 'scanner', 'unreal engine', 'deploybot', 'github enterprise', 'flurry', 'bitbucket', 'multimedia database', 'linear temporal logic', 'data visualization', 'ontology information science', 'hapi', 'certificate authority', 'geospatial analysis', 'evolutionary algorithm', 'gradle', 'kitematic', 'riak', 'laravel homestead', 'openshift', 'amazon machine learning', 'graphql', 'mongodb atlas', 'quantization signal processing', 'load and performance testing', 'virtual private cloud', 'codeanywhere', 'mongolab', 'solid modeling', 'component analysis', 'monitoring', 'support sales and marketing', 'electroencephalography', 'propositional calculus', 'response surface methodology', 'super resolution', 'fastlane', 'middleware', 'risk analysis engineering', 'spatial analysis', 'uikit', 'flow type', 'runtime system', 'human computer information retrieval', 'jekyll', 'internet of things', 'data cube', 'nightwatchjs', 'alpine linux', 'tailwind css', 'multiprocessing', 'graphical user interface', 'linux mint', 'dropbox', 'load balancing', 'monitoring aggregation', 'computational mathematics', 'semantic data model', 'spectrogram', 'message queue', 'semantic web', 'color vision', 'sensor array', 'application specific integrated circuit', 'couchdb', 'arduino', 'information flow information theory', 'interpolation', 'exception monitoring', 'rxjs', 'koding', 'codemirror', 'shared memory', 'google cloud datastore', 'computer science', 'virtual circuit', 'p2p', 'microsoft sql server', 'dynamic programming', 'braintree', 'apache hadoop', 'google cloud dns', 'intuitionistic logic', 'mariadb', 'postman', 'customer analytics', 'image quality', 'sendbird', 'marketing automation', 'durability', 'network management', 'visualization', 'medium', 'vim', 'optical character recognition', 'accounting', 'mocha', 'computer cluster', 'composite number', 'low pass filter', 'document classification', 'filter signal processing', 'online public access catalog', 'ubuntu', 'kernel linear algebra', 'blockchain', 'resource allocation', 'bitrise', 'dependency monitoring', 'sinatra', 'multi objective optimization', 'data system', 'auth0', 'patent visualisation', 'expectation maximization algorithm', 'amazon athena', 'nomad', 'encoding memory', 'topic model', 'peak signal to noise ratio', 'task management', 'functional programming', 'sensor tower', 'receiver operating characteristic', 'enterprise information security architecture', 'spacevim', 'pycharm', 'server configuration and automation', 'api documentation browser', 'documentation as a service & tools', 'state management library', 'push monkey', 'semantic network', 'code', 'fast fourier transform', 'data integrity', 'model based reasoning', 'grafana', 'amazon route 53', 'analysis of algorithms', 'schedule', 'authy', 'facial recognition', '3d reconstruction', 'feature detection', 'geographic information retrieval', 'detection theory', 'integrated services digital network', 'speech coding', 'apache lucene', 'decision problem', 'transactional email', 'openstack', 'context free language', 'image sensor', 'operational transformation', 'snippet', 'analysis of variance', 'data sharing', 'android sdk', 'requirejs', 'object oriented programming', 'distributed data store', 'google sheets', 'functional dependency', 'web forms', 'passive optical network', 'paw', 'apache flink', 'imgix', 'c', 'mobile backend', 'optical flow', 'crystal', 'dedicated cloud hosting', 'beanstalkd', 'sequelize', 'java build tools', 'control flow', 'teamcity', 'data science notebooks', 'devise', 'synthetic data', 'pubnub', 'state diagram', 'least squares', 'code review', 'inspec', 'loader.io', 'semantic similarity', 'optimization problem', 'cypress', 'stemming', 'discrete event simulation', 'anomaly detection', 'maximum a posteriori estimation', 'support vector machine', 'web server', 'bayesian network', 'hexo', 'kissmetrics', 'data transmission', 'high level synthesis', 'computer aided software engineering', 'embedded system', 'self management', 'pose', 'range query data structures', 'background subtraction', 'apache tomcat', 'software engineering', 'clef', 'random forest', 'phabricator', 'php mvc', 'image meta search', 'nosql database as a service', 'sentry', 'open postgresql monitoring', 'magento', 'parallel algorithm', 'angularui', 'markdown', 'sendgrid', 'mobile ui frameworks', 'continuous deployment', 'centos', 'pile', 'data type', 'hasura', 'regression analysis', 'contingency table', 'aws fargate', 'distributed memory', 'haskell', 'druid', 'guzzle', 'fingerprint recognition', 'computer security', 'material ui', 'sidekiq', 'machine learning tools', 'gitlab cd', 'webstorm', 'branch and bound', 'transport layer', 'landing pages', 'metadata', 'help desk', 'fraud detection', 'textmate', 'tree structure', 'faceted search', 'cryptocurrency', 'appium', 'information extraction', 'mobile database', 'adder', 'status page hosting', 'cocoa touch ios', 'cli', 'pusher', 'google cloud messaging', 'insomnia rest client', 'mobility management', 'hyperspectral imaging', 'apache http server', 'gnu bash', 'broadcasting', 'query language', 'redmine', 'vmware vsphere', 'spree', 'data warehouse', 'image processing', 'business process', 'operations management', 'expert system', 'issue tracking', 'programming paradigm', 'disqus', 'application and data', 'assets and media', 'erlang', 'minification', 'language acquisition', 'level of detail', 'data modeling', 'construction engineering', 'kanban', 'active appearance model', 'elixir', 'koa', 'wercker', 'trello', 'coordinate system', 'virtual reality', 'github', 'gogs', 'smoothing', 'gist', 'zeromq', 'sdn', 'hibernate', 'electronic engineering', 'helm', 'cucumber', 'lodash', 'webpack', 'api', 'conceptual model', 'record linkage', 'platform as a service tools', 'homebrew', 'yeoman', 'cloud monitoring', 'realm', 'hough transform', 'postgis', 'distributed database', 'wide area network', 'google analytics', 'perl', 'logical framework', 'compose', 'cryptographic protocol', 'reverse proxy', 'power management', 'greedy algorithm', 'neo4j', 'jupyter', 'ovh', 'namecheap', 'network architecture', 'application server', 'bibliographic database', 'autonomic computing', 'design', 'colorimetry', 'asynchronous communication', 'apache activemq', 'integrated circuit design', 'model checking', 'web service', 'information retrieval', 'conventional pci', 'signal processing', 'nginx', 'typescript', 'package manager', 'very large database', 'integrated development environment', 'amazon ebs', 'video processing', 'scikit learn', 'optical imaging', 'fault model', 'rotation', 'wakatime', 'mapbox', 'templating languages  extensions', 'benchmark computing', 'puppet labs', 'realtime backend api', 'elasticsearch', 'snyk', 'online algorithm', 'operating system', 'cognitive neuroscience of visual object recognition', 'sensor fusion', 'opencv', 'gearman', 'mastodon', 'microsoft iis', 'tornado', 'yarn', 'haptic technology', 'snowflake', 'infobox', 'goodness of fit', 'node.js process manager', 'knockoutjs', 'http', 'release', 'circumscription', 'serverless / task processing', 'stamplay', 'image retrieval', 'speaker recognition', 'android studio', 'riot', 'engineering drawing', 'geotechnical engineering', 'urban airship', 'noise reduction', 'semantic ui', 'dependency management', 'tcp / ip', 'k nearest neighbors algorithm', 'cloud hosting', 'database security', 'material design for angular', 'geoparsing', 'text segmentation', 'boolean algebra', 'ios', 'apollo', 'numerical stability', 'chrome extension', 'data management', 'dynamic range', 'lumen', 'sparkpost', 'metamodeling', 'material design lite', 'digital filter', 'simulation', 'amazon eks', 'hybrid algorithm', 'capybara', 'scalable vector graphics', 'linear regression', 'big data as a service', 'apache airflow', 'geckoboard', 'styled components', 'vuetify', 'entityrelationship model', 'data reduction', 'manufacturing engineering', 'inkwell', 'program transformation', 'live reloading', 'vagrant', 'distance transform', 'rough set', 'gitbucket', 'query string', 'doctrine', 'mobile computing', 'amazon dynamodb', 'hilbert huang transform', 'rust', 'arangodb', 'strongly connected component', 'grunt', 'time frequency analysis', 'laravel forge', 'website builder', 'structural engineering', 'compass', 'structured document', 'machine vision']\n"
     ]
    }
   ],
   "source": [
    "skills_list = []\n",
    "\n",
    "with open('skills.jsonl', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line)\n",
    "        label_parts = data[\"label\"].split('|')\n",
    "        \n",
    "        # Extract the label after the second '|', replace hyphens with spaces\n",
    "        extracted_label = label_parts[1].replace('-', ' ')\n",
    "        \n",
    "        # Append the extracted label to the list\n",
    "        skills_list.append(extracted_label)\n",
    "\n",
    "# Print the resulting list\n",
    "skills_list = list(set(skills_list))\n",
    "print(skills_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BS LEVEL', 'PHD LEVEL', 'MS LEVEL']\n"
     ]
    }
   ],
   "source": [
    "degrees_list = []\n",
    "\n",
    "with open('degrees.jsonl', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line)\n",
    "        label_parts = data[\"label\"].split('|')\n",
    "        \n",
    "        # Extract the label after the second '|', replace hyphens with spaces\n",
    "        extracted_label = label_parts[1].replace('-', ' ')\n",
    "        \n",
    "        # Append the extracted label to the list\n",
    "        degrees_list.append(extracted_label)\n",
    "\n",
    "# Print the resulting list\n",
    "degrees_list = list(set(degrees_list))\n",
    "print(degrees_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_degrees_majors = degrees_list + skills_list + majors_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_degrees_majors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag data - labels every skill/degree/major with a unique identifier - required for doc2vec model\n",
    "data = list(skills_degrees_majors)\n",
    "tagged_data = [TaggedDocument(words = word_tokenize(_d.lower()), tags = [str(i)]) for i, _d in enumerate(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "model = Doc2Vec(vector_size = 50,\n",
    "epochs = 40,\n",
    "alpha = 0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary building\n",
    "model.build_vocab(tagged_data)\n",
    "# Get the vocabulary keys\n",
    "keys = model.wv.key_to_index.keys()\n",
    "# Print the length of the vocabulary keys\n",
    "print(len(keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['bs', 'level'], tags=['0']),\n",
       " TaggedDocument(words=['phd', 'level'], tags=['1']),\n",
       " TaggedDocument(words=['ms', 'level'], tags=['2']),\n",
       " TaggedDocument(words=['mvc', 'tools'], tags=['3']),\n",
       " TaggedDocument(words=['spring'], tags=['4']),\n",
       " TaggedDocument(words=['vue.js'], tags=['5']),\n",
       " TaggedDocument(words=['data', 'analysis'], tags=['6']),\n",
       " TaggedDocument(words=['apache', 'zeppelin'], tags=['7']),\n",
       " TaggedDocument(words=['file', 'uploads'], tags=['8']),\n",
       " TaggedDocument(words=['random', 'access'], tags=['9']),\n",
       " TaggedDocument(words=['synthetic', 'aperture', 'radar'], tags=['10']),\n",
       " TaggedDocument(words=['phpunit'], tags=['11']),\n",
       " TaggedDocument(words=['image', 'analysis', 'api'], tags=['12']),\n",
       " TaggedDocument(words=['neural', 'coding'], tags=['13']),\n",
       " TaggedDocument(words=['correctness'], tags=['14']),\n",
       " TaggedDocument(words=['api', 'tools'], tags=['15']),\n",
       " TaggedDocument(words=['git'], tags=['16']),\n",
       " TaggedDocument(words=['query', 'optimization'], tags=['17']),\n",
       " TaggedDocument(words=['confluence'], tags=['18']),\n",
       " TaggedDocument(words=['metabase'], tags=['19']),\n",
       " TaggedDocument(words=['information', 'theory'], tags=['20']),\n",
       " TaggedDocument(words=['faceted', 'classification'], tags=['21']),\n",
       " TaggedDocument(words=['hugo'], tags=['22']),\n",
       " TaggedDocument(words=['classifier', 'linguistics'], tags=['23']),\n",
       " TaggedDocument(words=['semantic', 'computing'], tags=['24']),\n",
       " TaggedDocument(words=['jupyter', 'notebook'], tags=['25']),\n",
       " TaggedDocument(words=['analytics'], tags=['26']),\n",
       " TaggedDocument(words=['genetic', 'algorithm'], tags=['27']),\n",
       " TaggedDocument(words=['abstract', 'machine'], tags=['28']),\n",
       " TaggedDocument(words=['segmentation'], tags=['29']),\n",
       " TaggedDocument(words=['g', 'suite'], tags=['30']),\n",
       " TaggedDocument(words=['facial', 'expression', 'detection'], tags=['31']),\n",
       " TaggedDocument(words=['backbone.js'], tags=['32']),\n",
       " TaggedDocument(words=['critical', 'mass', 'software', 'engineering'], tags=['33']),\n",
       " TaggedDocument(words=['pattern', 'recognition'], tags=['34']),\n",
       " TaggedDocument(words=['gluon'], tags=['35']),\n",
       " TaggedDocument(words=['data', 'stores'], tags=['36']),\n",
       " TaggedDocument(words=['error', 'concealment'], tags=['37']),\n",
       " TaggedDocument(words=['messenger', 'platform'], tags=['38']),\n",
       " TaggedDocument(words=['simulated', 'annealing'], tags=['39']),\n",
       " TaggedDocument(words=['virtualization', 'platform'], tags=['40']),\n",
       " TaggedDocument(words=['wireframing'], tags=['41']),\n",
       " TaggedDocument(words=['utilities'], tags=['42']),\n",
       " TaggedDocument(words=['brute', 'force', 'search'], tags=['43']),\n",
       " TaggedDocument(words=['fragmentation', 'computing'], tags=['44']),\n",
       " TaggedDocument(words=['gatling'], tags=['45']),\n",
       " TaggedDocument(words=['read', 'write', 'memory'], tags=['46']),\n",
       " TaggedDocument(words=['latex'], tags=['47']),\n",
       " TaggedDocument(words=['opengl'], tags=['48']),\n",
       " TaggedDocument(words=['clicktale'], tags=['49']),\n",
       " TaggedDocument(words=['survey', 'widget'], tags=['50']),\n",
       " TaggedDocument(words=['edit', 'distance'], tags=['51']),\n",
       " TaggedDocument(words=['semantics'], tags=['52']),\n",
       " TaggedDocument(words=['augmented', 'reality'], tags=['53']),\n",
       " TaggedDocument(words=['content', 'writing'], tags=['54']),\n",
       " TaggedDocument(words=['dynamic', 'loading'], tags=['55']),\n",
       " TaggedDocument(words=['rocket'], tags=['56']),\n",
       " TaggedDocument(words=['amazon', 'ec2'], tags=['57']),\n",
       " TaggedDocument(words=['biomedical', 'engineering'], tags=['58']),\n",
       " TaggedDocument(words=['collision'], tags=['59']),\n",
       " TaggedDocument(words=['active', 'database'], tags=['60']),\n",
       " TaggedDocument(words=['real', 'time', 'data'], tags=['61']),\n",
       " TaggedDocument(words=['amazon', 'rds', 'for', 'postgresql'], tags=['62']),\n",
       " TaggedDocument(words=['next.js'], tags=['63']),\n",
       " TaggedDocument(words=['vuepress'], tags=['64']),\n",
       " TaggedDocument(words=['aws', 'cloudformation'], tags=['65']),\n",
       " TaggedDocument(words=['process', 'calculus'], tags=['66']),\n",
       " TaggedDocument(words=['asana'], tags=['67']),\n",
       " TaggedDocument(words=['telecommunications', 'network'], tags=['68']),\n",
       " TaggedDocument(words=['analog', 'to', 'digital', 'converter'], tags=['69']),\n",
       " TaggedDocument(words=['mobility', 'model'], tags=['70']),\n",
       " TaggedDocument(words=['time', 'sharing'], tags=['71']),\n",
       " TaggedDocument(words=['ruby'], tags=['72']),\n",
       " TaggedDocument(words=['chatbot'], tags=['73']),\n",
       " TaggedDocument(words=['docker', 'for', 'aws'], tags=['74']),\n",
       " TaggedDocument(words=['natural', 'language', 'understanding'], tags=['75']),\n",
       " TaggedDocument(words=['nuxt.js'], tags=['76']),\n",
       " TaggedDocument(words=['flip', 'flop'], tags=['77']),\n",
       " TaggedDocument(words=['multi', 'user'], tags=['78']),\n",
       " TaggedDocument(words=['optimizely'], tags=['79']),\n",
       " TaggedDocument(words=['tracking', 'system'], tags=['80']),\n",
       " TaggedDocument(words=['folksonomy'], tags=['81']),\n",
       " TaggedDocument(words=['self', 'hosted', 'blogging', '/', 'cms'], tags=['82']),\n",
       " TaggedDocument(words=['apiary'], tags=['83']),\n",
       " TaggedDocument(words=['user', 'feedback', 'as', 'a', 'service'], tags=['84']),\n",
       " TaggedDocument(words=['patent', 'classification'], tags=['85']),\n",
       " TaggedDocument(words=['directed', 'graph'], tags=['86']),\n",
       " TaggedDocument(words=['nativescript'], tags=['87']),\n",
       " TaggedDocument(words=['deadlock'], tags=['88']),\n",
       " TaggedDocument(words=['caddy'], tags=['89']),\n",
       " TaggedDocument(words=['sphinx'], tags=['90']),\n",
       " TaggedDocument(words=['international', 'trade'], tags=['91']),\n",
       " TaggedDocument(words=['documentation'], tags=['92']),\n",
       " TaggedDocument(words=['findability'], tags=['93']),\n",
       " TaggedDocument(words=['performance', 'metric'], tags=['94']),\n",
       " TaggedDocument(words=['amazon', 'sqs'], tags=['95']),\n",
       " TaggedDocument(words=['semaphore'], tags=['96']),\n",
       " TaggedDocument(words=['codenvy'], tags=['97']),\n",
       " TaggedDocument(words=['abstract', 'interpretation'], tags=['98']),\n",
       " TaggedDocument(words=['composite', 'index'], tags=['99']),\n",
       " TaggedDocument(words=['data', 'flow', 'diagram'], tags=['100']),\n",
       " TaggedDocument(words=['turing', 'machine'], tags=['101']),\n",
       " TaggedDocument(words=['mutual', 'information'], tags=['102']),\n",
       " TaggedDocument(words=['reliability', 'computer', 'networking'], tags=['103']),\n",
       " TaggedDocument(words=['high', 'availability'], tags=['104']),\n",
       " TaggedDocument(words=['memcachier'], tags=['105']),\n",
       " TaggedDocument(words=['netlify'], tags=['106']),\n",
       " TaggedDocument(words=['semantic', 'web', 'stack'], tags=['107']),\n",
       " TaggedDocument(words=['logistic', 'regression'], tags=['108']),\n",
       " TaggedDocument(words=['cepstrum'], tags=['109']),\n",
       " TaggedDocument(words=['cataloging'], tags=['110']),\n",
       " TaggedDocument(words=['mandrill'], tags=['111']),\n",
       " TaggedDocument(words=['searchretrieve', 'via', 'url'], tags=['112']),\n",
       " TaggedDocument(words=['frameworks', 'full', 'stack'], tags=['113']),\n",
       " TaggedDocument(words=['advertising'], tags=['114']),\n",
       " TaggedDocument(words=['curse', 'of', 'dimensionality'], tags=['115']),\n",
       " TaggedDocument(words=['tableau'], tags=['116']),\n",
       " TaggedDocument(words=['ecommerce'], tags=['117']),\n",
       " TaggedDocument(words=['residual'], tags=['118']),\n",
       " TaggedDocument(words=['google', 'tag', 'manager'], tags=['119']),\n",
       " TaggedDocument(words=['gatsby'], tags=['120']),\n",
       " TaggedDocument(words=['mongodb', 'hosting'], tags=['121']),\n",
       " TaggedDocument(words=['navigation', 'system'], tags=['122']),\n",
       " TaggedDocument(words=['kibana'], tags=['123']),\n",
       " TaggedDocument(words=['application', 'hosting'], tags=['124']),\n",
       " TaggedDocument(words=['point', 'to', 'point'], tags=['125']),\n",
       " TaggedDocument(words=['material', 'design', 'for', 'bootstrap'], tags=['126']),\n",
       " TaggedDocument(words=['formal', 'language'], tags=['127']),\n",
       " TaggedDocument(words=['time', 'tracking'], tags=['128']),\n",
       " TaggedDocument(words=['jest'], tags=['129']),\n",
       " TaggedDocument(words=['sql', 'database', 'as', 'a', 'service'], tags=['130']),\n",
       " TaggedDocument(words=['copy', 'protection'], tags=['131']),\n",
       " TaggedDocument(words=['superset'], tags=['132']),\n",
       " TaggedDocument(words=['information', 'seeking'], tags=['133']),\n",
       " TaggedDocument(words=['cloudflare'], tags=['134']),\n",
       " TaggedDocument(words=['web', 'components'], tags=['135']),\n",
       " TaggedDocument(words=['wireless'], tags=['136']),\n",
       " TaggedDocument(words=['google', 'app', 'maker'], tags=['137']),\n",
       " TaggedDocument(words=['encryption'], tags=['138']),\n",
       " TaggedDocument(words=['postcss'], tags=['139']),\n",
       " TaggedDocument(words=['bayesian', 'inference'], tags=['140']),\n",
       " TaggedDocument(words=['hhvm'], tags=['141']),\n",
       " TaggedDocument(words=['heroku', 'ci'], tags=['142']),\n",
       " TaggedDocument(words=['microservices', 'tools'], tags=['143']),\n",
       " TaggedDocument(words=['virtual', 'machine'], tags=['144']),\n",
       " TaggedDocument(words=['forensic', 'engineering'], tags=['145']),\n",
       " TaggedDocument(words=['voice', 'over', 'ip'], tags=['146']),\n",
       " TaggedDocument(words=['local', 'search', 'optimization'], tags=['147']),\n",
       " TaggedDocument(words=['content', 'delivery', 'network'], tags=['148']),\n",
       " TaggedDocument(words=['multicast'], tags=['149']),\n",
       " TaggedDocument(words=['f'], tags=['150']),\n",
       " TaggedDocument(words=['kanban', 'tool'], tags=['151']),\n",
       " TaggedDocument(words=['factorial', 'experiment'], tags=['152']),\n",
       " TaggedDocument(words=['network', 'delay'], tags=['153']),\n",
       " TaggedDocument(words=['fastly'], tags=['154']),\n",
       " TaggedDocument(words=['motion', 'analysis'], tags=['155']),\n",
       " TaggedDocument(words=['containers', 'as', 'a', 'service'], tags=['156']),\n",
       " TaggedDocument(words=['devdocs'], tags=['157']),\n",
       " TaggedDocument(words=['azure', 'machine', 'learning'], tags=['158']),\n",
       " TaggedDocument(words=['ajax'], tags=['159']),\n",
       " TaggedDocument(words=['rubocop'], tags=['160']),\n",
       " TaggedDocument(words=['serverless'], tags=['161']),\n",
       " TaggedDocument(words=['openresty'], tags=['162']),\n",
       " TaggedDocument(words=['google', 'cloud', 'storage'], tags=['163']),\n",
       " TaggedDocument(words=['javascript', 'utilities', 'libraries'], tags=['164']),\n",
       " TaggedDocument(words=['microsoft', 'bot', 'framework'], tags=['165']),\n",
       " TaggedDocument(words=['particle', 'filter'], tags=['166']),\n",
       " TaggedDocument(words=['email', 'marketing'], tags=['167']),\n",
       " TaggedDocument(words=['file', 'format'], tags=['168']),\n",
       " TaggedDocument(words=['time', 'of', 'arrival'], tags=['169']),\n",
       " TaggedDocument(words=['heroku'], tags=['170']),\n",
       " TaggedDocument(words=['secrets', 'management'], tags=['171']),\n",
       " TaggedDocument(words=['microdata', 'html'], tags=['172']),\n",
       " TaggedDocument(words=['network', 'layer'], tags=['173']),\n",
       " TaggedDocument(words=['yii'], tags=['174']),\n",
       " TaggedDocument(words=['homogeneity', 'statistics'], tags=['175']),\n",
       " TaggedDocument(words=['machine', 'learning'], tags=['176']),\n",
       " TaggedDocument(words=['amazon', 'cloudfront'], tags=['177']),\n",
       " TaggedDocument(words=['eclipse'], tags=['178']),\n",
       " TaggedDocument(words=['rackspace', 'cloud', 'servers'], tags=['179']),\n",
       " TaggedDocument(words=['ionic'], tags=['180']),\n",
       " TaggedDocument(words=['google', 'compute', 'engine'], tags=['181']),\n",
       " TaggedDocument(words=['stripe'], tags=['182']),\n",
       " TaggedDocument(words=['linear', 'search'], tags=['183']),\n",
       " TaggedDocument(words=['wavefront'], tags=['184']),\n",
       " TaggedDocument(words=['typeorm'], tags=['185']),\n",
       " TaggedDocument(words=['first', 'order', 'logic'], tags=['186']),\n",
       " TaggedDocument(words=['debian'], tags=['187']),\n",
       " TaggedDocument(words=['traffic', 'engineering'], tags=['188']),\n",
       " TaggedDocument(words=['web', 'starter', 'kit'], tags=['189']),\n",
       " TaggedDocument(words=['smart', 'card'], tags=['190']),\n",
       " TaggedDocument(words=['swagger', 'ui'], tags=['191']),\n",
       " TaggedDocument(words=['julia'], tags=['192']),\n",
       " TaggedDocument(words=['dns', 'management'], tags=['193']),\n",
       " TaggedDocument(words=['preactjs'], tags=['194']),\n",
       " TaggedDocument(words=['bottom', 'up', 'model'], tags=['195']),\n",
       " TaggedDocument(words=['engineering'], tags=['196']),\n",
       " TaggedDocument(words=['specification'], tags=['197']),\n",
       " TaggedDocument(words=['neural', 'network'], tags=['198']),\n",
       " TaggedDocument(words=['redash'], tags=['199']),\n",
       " TaggedDocument(words=['activity', 'recognition'], tags=['200']),\n",
       " TaggedDocument(words=['time', 'series'], tags=['201']),\n",
       " TaggedDocument(words=['maxcdn'], tags=['202']),\n",
       " TaggedDocument(words=['amazon', 'kinesis'], tags=['203']),\n",
       " TaggedDocument(words=['varnish'], tags=['204']),\n",
       " TaggedDocument(words=['programming', 'languages'], tags=['205']),\n",
       " TaggedDocument(words=['knowledge', 'extraction'], tags=['206']),\n",
       " TaggedDocument(words=['domain', 'knowledge'], tags=['207']),\n",
       " TaggedDocument(words=['random', 'projection'], tags=['208']),\n",
       " TaggedDocument(words=['information', 'management'], tags=['209']),\n",
       " TaggedDocument(words=['semi', 'supervised', 'learning'], tags=['210']),\n",
       " TaggedDocument(words=['tfidf'], tags=['211']),\n",
       " TaggedDocument(words=['persistence', 'computer', 'science'], tags=['212']),\n",
       " TaggedDocument(words=['amazon', 'cognito'], tags=['213']),\n",
       " TaggedDocument(words=['similarity', 'measure'], tags=['214']),\n",
       " TaggedDocument(words=['ansible'], tags=['215']),\n",
       " TaggedDocument(words=['network', 'topology'], tags=['216']),\n",
       " TaggedDocument(words=['sql'], tags=['217']),\n",
       " TaggedDocument(words=['communication', 'in', 'small', 'groups'], tags=['218']),\n",
       " TaggedDocument(words=['ground', 'truth'], tags=['219']),\n",
       " TaggedDocument(words=['apigee'], tags=['220']),\n",
       " TaggedDocument(words=['compressed', 'sensing'], tags=['221']),\n",
       " TaggedDocument(words=['mobile', 'station'], tags=['222']),\n",
       " TaggedDocument(words=['wireless', 'ad', 'hoc', 'network'], tags=['223']),\n",
       " TaggedDocument(words=['jruby'], tags=['224']),\n",
       " TaggedDocument(words=['logrocket'], tags=['225']),\n",
       " TaggedDocument(words=['false', 'positive', 'rate'], tags=['226']),\n",
       " TaggedDocument(words=['sonatype', 'nexus'], tags=['227']),\n",
       " TaggedDocument(words=['codeship'], tags=['228']),\n",
       " TaggedDocument(words=['pandas'], tags=['229']),\n",
       " TaggedDocument(words=['scala'], tags=['230']),\n",
       " TaggedDocument(words=['docker', 'cloud'], tags=['231']),\n",
       " TaggedDocument(words=['microcomputer'], tags=['232']),\n",
       " TaggedDocument(words=['gaussian', 'process'], tags=['233']),\n",
       " TaggedDocument(words=['haproxy'], tags=['234']),\n",
       " TaggedDocument(words=['supervisory', 'control'], tags=['235']),\n",
       " TaggedDocument(words=['computer', 'graphics'], tags=['236']),\n",
       " TaggedDocument(words=['load', 'management'], tags=['237']),\n",
       " TaggedDocument(words=['raspberry', 'pi'], tags=['238']),\n",
       " TaggedDocument(words=['canonical', 'model'], tags=['239']),\n",
       " TaggedDocument(words=['mysql'], tags=['240']),\n",
       " TaggedDocument(words=['reachability'], tags=['241']),\n",
       " TaggedDocument(words=['industrial', 'engineering'], tags=['242']),\n",
       " TaggedDocument(words=['access', 'method'], tags=['243']),\n",
       " TaggedDocument(words=['material', 'design'], tags=['244']),\n",
       " TaggedDocument(words=['amazon', 'cloudwatch'], tags=['245']),\n",
       " TaggedDocument(words=['web', 'development'], tags=['246']),\n",
       " TaggedDocument(words=['latency', 'engineering'], tags=['247']),\n",
       " TaggedDocument(words=['f', '#'], tags=['248']),\n",
       " TaggedDocument(words=['keycdn'], tags=['249']),\n",
       " TaggedDocument(words=['apache', 'cordova'], tags=['250']),\n",
       " TaggedDocument(words=['opensuse'], tags=['251']),\n",
       " TaggedDocument(words=['clubhouse'], tags=['252']),\n",
       " TaggedDocument(words=['redux'], tags=['253']),\n",
       " TaggedDocument(words=['clinicalkey'], tags=['254']),\n",
       " TaggedDocument(words=['network', 'security'], tags=['255']),\n",
       " TaggedDocument(words=['temporal', 'database'], tags=['256']),\n",
       " TaggedDocument(words=['communication', 'complexity'], tags=['257']),\n",
       " TaggedDocument(words=['gitlab'], tags=['258']),\n",
       " TaggedDocument(words=['tree', 'automaton'], tags=['259']),\n",
       " TaggedDocument(words=['meteor'], tags=['260']),\n",
       " TaggedDocument(words=['salesforce', 'sales', 'cloud'], tags=['261']),\n",
       " TaggedDocument(words=['aws', 'lambda'], tags=['262']),\n",
       " TaggedDocument(words=['js', 'task', 'runners'], tags=['263']),\n",
       " TaggedDocument(words=['dash'], tags=['264']),\n",
       " TaggedDocument(words=['dynamic', 'data'], tags=['265']),\n",
       " TaggedDocument(words=['gradient', 'descent'], tags=['266']),\n",
       " TaggedDocument(words=['api.ai'], tags=['267']),\n",
       " TaggedDocument(words=['link', 'relation'], tags=['268']),\n",
       " TaggedDocument(words=['sliding', 'window', 'protocol'], tags=['269']),\n",
       " TaggedDocument(words=['decision', 'tree'], tags=['270']),\n",
       " TaggedDocument(words=['google', 'scholar', 'and', 'academic', 'libraries'], tags=['271']),\n",
       " TaggedDocument(words=['webflow'], tags=['272']),\n",
       " TaggedDocument(words=['translation', 'service'], tags=['273']),\n",
       " TaggedDocument(words=['deductive', 'database'], tags=['274']),\n",
       " TaggedDocument(words=['kotlin'], tags=['275']),\n",
       " TaggedDocument(words=['read', 'only', 'memory'], tags=['276']),\n",
       " TaggedDocument(words=['drupal'], tags=['277']),\n",
       " TaggedDocument(words=['javascript'], tags=['278']),\n",
       " TaggedDocument(words=['front', 'end', 'package', 'manager'], tags=['279']),\n",
       " TaggedDocument(words=['sass'], tags=['280']),\n",
       " TaggedDocument(words=['ava'], tags=['281']),\n",
       " TaggedDocument(words=['automaton'], tags=['282']),\n",
       " TaggedDocument(words=['bamboo'], tags=['283']),\n",
       " TaggedDocument(words=['supercomputer'], tags=['284']),\n",
       " TaggedDocument(words=['circleci'], tags=['285']),\n",
       " TaggedDocument(words=['unified', 'modeling', 'language'], tags=['286']),\n",
       " TaggedDocument(words=['electronic', 'document'], tags=['287']),\n",
       " TaggedDocument(words=['microprocessor'], tags=['288']),\n",
       " TaggedDocument(words=['monitoring', 'tools'], tags=['289']),\n",
       " TaggedDocument(words=['deployment', 'as', 'a', 'service'], tags=['290']),\n",
       " TaggedDocument(words=['discriminative', 'model'], tags=['291']),\n",
       " TaggedDocument(words=['structural', 'equation', 'modeling'], tags=['292']),\n",
       " TaggedDocument(words=['decidability'], tags=['293']),\n",
       " TaggedDocument(words=['knowledge', 'representation', 'and', 'reasoning'], tags=['294']),\n",
       " TaggedDocument(words=['finagle'], tags=['295']),\n",
       " TaggedDocument(words=['prometheus'], tags=['296']),\n",
       " TaggedDocument(words=['text', 'mining'], tags=['297']),\n",
       " TaggedDocument(words=['commenting', 'service'], tags=['298']),\n",
       " TaggedDocument(words=['strips'], tags=['299']),\n",
       " TaggedDocument(words=['datalog'], tags=['300']),\n",
       " TaggedDocument(words=['digital', 'signature'], tags=['301']),\n",
       " TaggedDocument(words=['queues'], tags=['302']),\n",
       " TaggedDocument(words=['dart'], tags=['303']),\n",
       " TaggedDocument(words=['awx'], tags=['304']),\n",
       " TaggedDocument(words=['aspect', 'oriented', 'programming'], tags=['305']),\n",
       " TaggedDocument(words=['ethernet'], tags=['306']),\n",
       " TaggedDocument(words=['ubiquitous', 'computing'], tags=['307']),\n",
       " TaggedDocument(words=['fault', 'tolerance'], tags=['308']),\n",
       " TaggedDocument(words=['clientserver', 'model'], tags=['309']),\n",
       " TaggedDocument(words=['document', 'management', 'system'], tags=['310']),\n",
       " TaggedDocument(words=['multivariate', 'statistics'], tags=['311']),\n",
       " TaggedDocument(words=['asp.net'], tags=['312']),\n",
       " TaggedDocument(words=['computer', 'graphics', 'images'], tags=['313']),\n",
       " TaggedDocument(words=['multimedia'], tags=['314']),\n",
       " TaggedDocument(words=['iterative', 'reconstruction'], tags=['315']),\n",
       " TaggedDocument(words=['gunicorn'], tags=['316']),\n",
       " TaggedDocument(words=['breadth', 'first', 'search'], tags=['317']),\n",
       " TaggedDocument(words=['spreadsheets', 'online'], tags=['318']),\n",
       " TaggedDocument(words=['word', 'sense', 'disambiguation'], tags=['319']),\n",
       " TaggedDocument(words=['regular', 'language'], tags=['320']),\n",
       " TaggedDocument(words=['reverse', 'engineering'], tags=['321']),\n",
       " TaggedDocument(words=['figma'], tags=['322']),\n",
       " TaggedDocument(words=['bag', 'of', 'words', 'model'], tags=['323']),\n",
       " TaggedDocument(words=['thresholding'], tags=['324']),\n",
       " TaggedDocument(words=['named', 'entity'], tags=['325']),\n",
       " TaggedDocument(words=['highcharts', 'js'], tags=['326']),\n",
       " TaggedDocument(words=['information', 'model'], tags=['327']),\n",
       " TaggedDocument(words=['subject', 'access'], tags=['328']),\n",
       " TaggedDocument(words=['uppy'], tags=['329']),\n",
       " TaggedDocument(words=['mercurial'], tags=['330']),\n",
       " TaggedDocument(words=['computer', 'data', 'storage'], tags=['331']),\n",
       " TaggedDocument(words=['xml'], tags=['332']),\n",
       " TaggedDocument(words=['figure', 'of', 'merit'], tags=['333']),\n",
       " TaggedDocument(words=['flat', 'panel', 'display'], tags=['334']),\n",
       " TaggedDocument(words=['zend', 'framework'], tags=['335']),\n",
       " TaggedDocument(words=['amazon', 'elasticsearch', 'service'], tags=['336']),\n",
       " TaggedDocument(words=['file', 'storage'], tags=['337']),\n",
       " TaggedDocument(words=['node', 'networking'], tags=['338']),\n",
       " TaggedDocument(words=['bibliometrics'], tags=['339']),\n",
       " TaggedDocument(words=['localhost', 'tools'], tags=['340']),\n",
       " TaggedDocument(words=['redis', 'hosting'], tags=['341']),\n",
       " TaggedDocument(words=['php'], tags=['342']),\n",
       " TaggedDocument(words=['google', 'cloud', 'sql'], tags=['343']),\n",
       " TaggedDocument(words=['react'], tags=['344']),\n",
       " TaggedDocument(words=['marine', 'engineering'], tags=['345']),\n",
       " TaggedDocument(words=['pushdown', 'automaton'], tags=['346']),\n",
       " TaggedDocument(words=['publishing'], tags=['347']),\n",
       " TaggedDocument(words=['econometric', 'model'], tags=['348']),\n",
       " TaggedDocument(words=['response', 'time'], tags=['349']),\n",
       " TaggedDocument(words=['memcached'], tags=['350']),\n",
       " TaggedDocument(words=['github', 'pages'], tags=['351']),\n",
       " TaggedDocument(words=['git', 'tools'], tags=['352']),\n",
       " TaggedDocument(words=['raml'], tags=['353']),\n",
       " TaggedDocument(words=['codeigniter'], tags=['354']),\n",
       " TaggedDocument(words=['apache', 'spark'], tags=['355']),\n",
       " TaggedDocument(words=['omniauth'], tags=['356']),\n",
       " TaggedDocument(words=['multilevel', 'model'], tags=['357']),\n",
       " TaggedDocument(words=['.net'], tags=['358']),\n",
       " TaggedDocument(words=['react.js', 'boilerplate'], tags=['359']),\n",
       " TaggedDocument(words=['jquery', 'mobile'], tags=['360']),\n",
       " TaggedDocument(words=['static', 'timing', 'analysis'], tags=['361']),\n",
       " TaggedDocument(words=['web', 'document'], tags=['362']),\n",
       " TaggedDocument(words=['matlab'], tags=['363']),\n",
       " TaggedDocument(words=['rule', 'induction'], tags=['364']),\n",
       " TaggedDocument(words=['result', 'set'], tags=['365']),\n",
       " TaggedDocument(words=['azure', 'functions'], tags=['366']),\n",
       " TaggedDocument(words=['disjunctive', 'normal', 'form'], tags=['367']),\n",
       " TaggedDocument(words=['round', 'trip', 'delay', 'time'], tags=['368']),\n",
       " TaggedDocument(words=['akamai'], tags=['369']),\n",
       " TaggedDocument(words=['control', 'engineering'], tags=['370']),\n",
       " TaggedDocument(words=['object', 'detection'], tags=['371']),\n",
       " TaggedDocument(words=['data', 'science', 'tools'], tags=['372']),\n",
       " TaggedDocument(words=['natural', 'language', 'processing'], tags=['373']),\n",
       " TaggedDocument(words=['rollbar'], tags=['374']),\n",
       " TaggedDocument(words=['shrinkage'], tags=['375']),\n",
       " TaggedDocument(words=['codec'], tags=['376']),\n",
       " TaggedDocument(words=['neovim'], tags=['377']),\n",
       " TaggedDocument(words=['surge'], tags=['378']),\n",
       " TaggedDocument(words=['ratchet'], tags=['379']),\n",
       " TaggedDocument(words=['zoho', 'crm'], tags=['380']),\n",
       " TaggedDocument(words=['bayesian', 'probability'], tags=['381']),\n",
       " TaggedDocument(words=['azure'], tags=['382']),\n",
       " TaggedDocument(words=['machine', 'learning', 'as', 'a', 'service'], tags=['383']),\n",
       " TaggedDocument(words=['central', 'processing', 'unit'], tags=['384']),\n",
       " TaggedDocument(words=['cross', 'validation'], tags=['385']),\n",
       " TaggedDocument(words=['impala'], tags=['386']),\n",
       " TaggedDocument(words=['conditional', 'random', 'field'], tags=['387']),\n",
       " TaggedDocument(words=['sonarqube'], tags=['388']),\n",
       " TaggedDocument(words=['rails'], tags=['389']),\n",
       " TaggedDocument(words=['errors', 'in', 'variables', 'models'], tags=['390']),\n",
       " TaggedDocument(words=['mobile', 'prototyping'], tags=['391']),\n",
       " TaggedDocument(words=['replication', 'computing'], tags=['392']),\n",
       " TaggedDocument(words=['index', 'term'], tags=['393']),\n",
       " TaggedDocument(words=['minio'], tags=['394']),\n",
       " TaggedDocument(words=['jquery', 'ui'], tags=['395']),\n",
       " TaggedDocument(words=['functional', 'testing'], tags=['396']),\n",
       " TaggedDocument(words=['fuzzy', 'logic'], tags=['397']),\n",
       " TaggedDocument(words=['bulma'], tags=['398']),\n",
       " TaggedDocument(words=['pattern', 'recognition', 'psychology'], tags=['399']),\n",
       " TaggedDocument(words=['woopra'], tags=['400']),\n",
       " TaggedDocument(words=['computer', 'network'], tags=['401']),\n",
       " TaggedDocument(words=['google', 'cloud', 'bigtable'], tags=['402']),\n",
       " TaggedDocument(words=['knowledge', 'retrieval'], tags=['403']),\n",
       " TaggedDocument(words=['adobe', 'xd'], tags=['404']),\n",
       " TaggedDocument(words=['amazon', 'api', 'gateway'], tags=['405']),\n",
       " TaggedDocument(words=['background', 'processing'], tags=['406']),\n",
       " TaggedDocument(words=['coveralls'], tags=['407']),\n",
       " TaggedDocument(words=['active', 'shape', 'model'], tags=['408']),\n",
       " TaggedDocument(words=['code', 'climate'], tags=['409']),\n",
       " TaggedDocument(words=['javascript', 'framework', 'components'], tags=['410']),\n",
       " TaggedDocument(words=['aws', 'opsworks'], tags=['411']),\n",
       " TaggedDocument(words=['spring', 'cloud'], tags=['412']),\n",
       " TaggedDocument(words=['scalability'], tags=['413']),\n",
       " TaggedDocument(words=['mining', 'engineering'], tags=['414']),\n",
       " TaggedDocument(words=['typeform'], tags=['415']),\n",
       " TaggedDocument(words=['power', 'control'], tags=['416']),\n",
       " TaggedDocument(words=['authentication'], tags=['417']),\n",
       " TaggedDocument(words=['canonical', 'correlation'], tags=['418']),\n",
       " TaggedDocument(words=['feature', 'vector'], tags=['419']),\n",
       " TaggedDocument(words=['framer'], tags=['420']),\n",
       " TaggedDocument(words=['ibm', 'db2'], tags=['421']),\n",
       " TaggedDocument(words=['optical', 'transfer', 'function'], tags=['422']),\n",
       " TaggedDocument(words=['gitlab', 'ci'], tags=['423']),\n",
       " TaggedDocument(words=['sauce', 'labs'], tags=['424']),\n",
       " TaggedDocument(words=['actuarial', 'science'], tags=['425']),\n",
       " TaggedDocument(words=['scale', 'space'], tags=['426']),\n",
       " TaggedDocument(words=['gulp.js'], tags=['427']),\n",
       " TaggedDocument(words=['bitcoin'], tags=['428']),\n",
       " TaggedDocument(words=['apache', 'maven'], tags=['429']),\n",
       " TaggedDocument(words=['dimensionality', 'reduction'], tags=['430']),\n",
       " TaggedDocument(words=['beta', 'testing', '&', 'mobile', 'app', 'distribution'], tags=['431']),\n",
       " TaggedDocument(words=['invision'], tags=['432']),\n",
       " TaggedDocument(words=['remote', 'procedure', 'call'], tags=['433']),\n",
       " TaggedDocument(words=['code', 'generation'], tags=['434']),\n",
       " TaggedDocument(words=['deco'], tags=['435']),\n",
       " TaggedDocument(words=['payment', 'services'], tags=['436']),\n",
       " TaggedDocument(words=['topic', 'maps'], tags=['437']),\n",
       " TaggedDocument(words=['telegram'], tags=['438']),\n",
       " TaggedDocument(words=['clojurescript'], tags=['439']),\n",
       " TaggedDocument(words=['google', 'drive'], tags=['440']),\n",
       " TaggedDocument(words=['dynamic', 'testing'], tags=['441']),\n",
       " TaggedDocument(words=['actuator'], tags=['442']),\n",
       " TaggedDocument(words=['mixture', 'model'], tags=['443']),\n",
       " TaggedDocument(words=['critical', 'path', 'method'], tags=['444']),\n",
       " TaggedDocument(words=['etcd'], tags=['445']),\n",
       " TaggedDocument(words=['financial', 'system'], tags=['446']),\n",
       " TaggedDocument(words=['next', 'generation', 'network'], tags=['447']),\n",
       " TaggedDocument(words=['r'], tags=['448']),\n",
       " TaggedDocument(words=['pingdom'], tags=['449']),\n",
       " TaggedDocument(words=['data', 'pre', 'processing'], tags=['450']),\n",
       " TaggedDocument(words=['expander', 'graph'], tags=['451']),\n",
       " TaggedDocument(words=['linear', 'model'], tags=['452']),\n",
       " TaggedDocument(words=['istio'], tags=['453']),\n",
       " TaggedDocument(words=['aws', 'codecommit'], tags=['454']),\n",
       " TaggedDocument(words=['medical', 'imaging'], tags=['455']),\n",
       " TaggedDocument(words=['react', 'hot', 'loader'], tags=['456']),\n",
       " TaggedDocument(words=['binary', 'search', 'tree'], tags=['457']),\n",
       " TaggedDocument(words=['google', 'cloud', 'vision', 'api'], tags=['458']),\n",
       " TaggedDocument(words=['object', 'document', 'mapper'], tags=['459']),\n",
       " TaggedDocument(words=['gitkraken'], tags=['460']),\n",
       " TaggedDocument(words=['pytorch'], tags=['461']),\n",
       " TaggedDocument(words=['appveyor'], tags=['462']),\n",
       " TaggedDocument(words=['relative', 'record', 'data', 'set'], tags=['463']),\n",
       " TaggedDocument(words=['realtime', 'analytics'], tags=['464']),\n",
       " TaggedDocument(words=['self', 'organization'], tags=['465']),\n",
       " TaggedDocument(words=['shortest', 'path', 'problem'], tags=['466']),\n",
       " TaggedDocument(words=['clustring'], tags=['467']),\n",
       " TaggedDocument(words=['google', 'cloud', 'container', 'builder'], tags=['468']),\n",
       " TaggedDocument(words=['aws', 'iam'], tags=['469']),\n",
       " TaggedDocument(words=['plotly'], tags=['470']),\n",
       " TaggedDocument(words=['logstash'], tags=['471']),\n",
       " TaggedDocument(words=['shippable'], tags=['472']),\n",
       " TaggedDocument(words=['programmable', 'logic', 'device'], tags=['473']),\n",
       " TaggedDocument(words=['framework7'], tags=['474']),\n",
       " TaggedDocument(words=['big', 'data', 'tools'], tags=['475']),\n",
       " TaggedDocument(words=['amazon', 'kinesis', 'firehose'], tags=['476']),\n",
       " TaggedDocument(words=['headless', 'browsers'], tags=['477']),\n",
       " TaggedDocument(words=['kalman', 'filter'], tags=['478']),\n",
       " TaggedDocument(words=['qt'], tags=['479']),\n",
       " TaggedDocument(words=['hubspot'], tags=['480']),\n",
       " TaggedDocument(words=['mathematical', 'logic'], tags=['481']),\n",
       " TaggedDocument(words=['arboriculture'], tags=['482']),\n",
       " TaggedDocument(words=['sourcetree'], tags=['483']),\n",
       " TaggedDocument(words=['frontend'], tags=['484']),\n",
       " TaggedDocument(words=['triangulation', 'social', 'science'], tags=['485']),\n",
       " TaggedDocument(words=['multispectral', 'image'], tags=['486']),\n",
       " TaggedDocument(words=['speech', 'recognition'], tags=['487']),\n",
       " TaggedDocument(words=['regular', 'expression'], tags=['488']),\n",
       " TaggedDocument(words=['graphic', 'design'], tags=['489']),\n",
       " TaggedDocument(words=['amazon', 'ec2', 'container', 'service'], tags=['490']),\n",
       " TaggedDocument(words=['kong'], tags=['491']),\n",
       " TaggedDocument(words=['key', 'lock'], tags=['492']),\n",
       " TaggedDocument(words=['description', 'logic'], tags=['493']),\n",
       " TaggedDocument(words=['hogan.js'], tags=['494']),\n",
       " TaggedDocument(words=['distributed', 'system'], tags=['495']),\n",
       " TaggedDocument(words=['cobol'], tags=['496']),\n",
       " TaggedDocument(words=['testflight'], tags=['497']),\n",
       " TaggedDocument(words=['unity'], tags=['498']),\n",
       " TaggedDocument(words=['field', 'of', 'view'], tags=['499']),\n",
       " TaggedDocument(words=['tools', 'for', 'text', 'editors'], tags=['500']),\n",
       " TaggedDocument(words=['boolean', 'expression'], tags=['501']),\n",
       " TaggedDocument(words=['robustness', 'computer', 'science'], tags=['502']),\n",
       " TaggedDocument(words=['distributed', 'computing', 'environment'], tags=['503']),\n",
       " TaggedDocument(words=['word', 'error', 'rate'], tags=['504']),\n",
       " TaggedDocument(words=['overlay', 'network'], tags=['505']),\n",
       " TaggedDocument(words=['mobile', 'push', 'messaging'], tags=['506']),\n",
       " TaggedDocument(words=['hotjar'], tags=['507']),\n",
       " TaggedDocument(words=['django'], tags=['508']),\n",
       " TaggedDocument(words=['artificial', 'neural', 'network'], tags=['509']),\n",
       " TaggedDocument(words=['pushwoosh'], tags=['510']),\n",
       " TaggedDocument(words=['visual', 'studio', 'team', 'services'], tags=['511']),\n",
       " TaggedDocument(words=['vue'], tags=['512']),\n",
       " TaggedDocument(words=['apache', 'kafka'], tags=['513']),\n",
       " TaggedDocument(words=['telephony'], tags=['514']),\n",
       " TaggedDocument(words=['query', 'expansion'], tags=['515']),\n",
       " TaggedDocument(words=['kullbackleibler', 'divergence'], tags=['516']),\n",
       " TaggedDocument(words=['redis', 'cloud'], tags=['517']),\n",
       " TaggedDocument(words=['spread', 'spectrum'], tags=['518']),\n",
       " TaggedDocument(words=['mobile', 'continuous', 'integration'], tags=['519']),\n",
       " TaggedDocument(words=['datadog'], tags=['520']),\n",
       " TaggedDocument(words=['js', 'build', 'tools'], tags=['521']),\n",
       " TaggedDocument(words=['mobile', 'testing', 'frameworks'], tags=['522']),\n",
       " TaggedDocument(words=['linode'], tags=['523']),\n",
       " TaggedDocument(words=['inference'], tags=['524']),\n",
       " TaggedDocument(words=['markup', 'language'], tags=['525']),\n",
       " TaggedDocument(words=['wavelet'], tags=['526']),\n",
       " TaggedDocument(words=['notepad'], tags=['527']),\n",
       " TaggedDocument(words=['cluster', 'management'], tags=['528']),\n",
       " TaggedDocument(words=['biometrics'], tags=['529']),\n",
       " TaggedDocument(words=['rule', 'based', 'system'], tags=['530']),\n",
       " TaggedDocument(words=['recurly'], tags=['531']),\n",
       " TaggedDocument(words=['formal', 'verification'], tags=['532']),\n",
       " TaggedDocument(words=['telegram', 'bot', 'api'], tags=['533']),\n",
       " TaggedDocument(words=['change', 'detection'], tags=['534']),\n",
       " TaggedDocument(words=['apache', 'mesos'], tags=['535']),\n",
       " TaggedDocument(words=['1password'], tags=['536']),\n",
       " TaggedDocument(words=['image', 'registration'], tags=['537']),\n",
       " TaggedDocument(words=['jsdoc'], tags=['538']),\n",
       " TaggedDocument(words=['visual', 'programming', 'language'], tags=['539']),\n",
       " TaggedDocument(words=['codacy'], tags=['540']),\n",
       " TaggedDocument(words=['fullstory'], tags=['541']),\n",
       " TaggedDocument(words=['cloud', 'ide'], tags=['542']),\n",
       " TaggedDocument(words=['adaptive', 'system'], tags=['543']),\n",
       " TaggedDocument(words=['rails', 'api'], tags=['544']),\n",
       " TaggedDocument(words=['prognostics'], tags=['545']),\n",
       " TaggedDocument(words=['line', 'of', 'sight'], tags=['546']),\n",
       " TaggedDocument(words=['template', 'matching'], tags=['547']),\n",
       " TaggedDocument(words=['locust'], tags=['548']),\n",
       " TaggedDocument(words=['confirmatory', 'factor', 'analysis'], tags=['549']),\n",
       " TaggedDocument(words=['buffer', 'overflow'], tags=['550']),\n",
       " TaggedDocument(words=['fluentd'], tags=['551']),\n",
       " TaggedDocument(words=['natural', 'language'], tags=['552']),\n",
       " TaggedDocument(words=['motion', 'compensation'], tags=['553']),\n",
       " TaggedDocument(words=['npm'], tags=['554']),\n",
       " TaggedDocument(words=['mongoid'], tags=['555']),\n",
       " TaggedDocument(words=['noisy', 'data'], tags=['556']),\n",
       " TaggedDocument(words=['dnsimple'], tags=['557']),\n",
       " TaggedDocument(words=['mongodb', 'stitch'], tags=['558']),\n",
       " TaggedDocument(words=['grails'], tags=['559']),\n",
       " TaggedDocument(words=['resque'], tags=['560']),\n",
       " TaggedDocument(words=['linear', 'discriminant', 'analysis'], tags=['561']),\n",
       " TaggedDocument(words=['knex.js'], tags=['562']),\n",
       " TaggedDocument(words=['training', 'model'], tags=['563']),\n",
       " TaggedDocument(words=['region', 'of', 'interest'], tags=['564']),\n",
       " TaggedDocument(words=['aws', 'elastic', 'beanstalk'], tags=['565']),\n",
       " TaggedDocument(words=['filestack'], tags=['566']),\n",
       " TaggedDocument(words=['coffeescript'], tags=['567']),\n",
       " TaggedDocument(words=['arch', 'linux'], tags=['568']),\n",
       " TaggedDocument(words=['traffic', 'model'], tags=['569']),\n",
       " TaggedDocument(words=['kendo', 'ui'], tags=['570']),\n",
       " TaggedDocument(words=['routing', 'protocol'], tags=['571']),\n",
       " TaggedDocument(words=['satisfiability'], tags=['572']),\n",
       " TaggedDocument(words=['feathersjs'], tags=['573']),\n",
       " TaggedDocument(words=['phpstorm'], tags=['574']),\n",
       " TaggedDocument(words=['apache', 'storm'], tags=['575']),\n",
       " TaggedDocument(words=['expressjs'], tags=['576']),\n",
       " TaggedDocument(words=['noise', 'measurement'], tags=['577']),\n",
       " TaggedDocument(words=['computer', 'engineering'], tags=['578']),\n",
       " TaggedDocument(words=['clion'], tags=['579']),\n",
       " TaggedDocument(words=['local', 'area', 'network'], tags=['580']),\n",
       " TaggedDocument(words=['generalization', 'error'], tags=['581']),\n",
       " TaggedDocument(words=['document', 'retrieval'], tags=['582']),\n",
       " TaggedDocument(words=['morphology', 'linguistics'], tags=['583']),\n",
       " TaggedDocument(words=['linear', 'programming'], tags=['584']),\n",
       " TaggedDocument(words=['sequel', 'pro'], tags=['585']),\n",
       " TaggedDocument(words=['computer', 'vision'], tags=['586']),\n",
       " TaggedDocument(words=['stylelint'], tags=['587']),\n",
       " TaggedDocument(words=['mobile', 'error', 'monitoring'], tags=['588']),\n",
       " TaggedDocument(words=['modal', 'logic'], tags=['589']),\n",
       " TaggedDocument(words=['particle', 'swarm', 'optimization'], tags=['590']),\n",
       " TaggedDocument(words=['information', 'retrieval', 'query', 'language'], tags=['591']),\n",
       " TaggedDocument(words=['point', 'location'], tags=['592']),\n",
       " TaggedDocument(words=['reactiveui'], tags=['593']),\n",
       " TaggedDocument(words=['computational', 'geometry'], tags=['594']),\n",
       " TaggedDocument(words=['business', 'tools'], tags=['595']),\n",
       " TaggedDocument(words=['d3.js'], tags=['596']),\n",
       " TaggedDocument(words=['built', 'in', 'self', 'test'], tags=['597']),\n",
       " TaggedDocument(words=['google', 'maps'], tags=['598']),\n",
       " TaggedDocument(words=['sma'], tags=['599']),\n",
       " TaggedDocument(words=['prosthesis'], tags=['600']),\n",
       " TaggedDocument(words=['geotagging'], tags=['601']),\n",
       " TaggedDocument(words=['multidimensional', 'scaling'], tags=['602']),\n",
       " TaggedDocument(words=['analysis', 'of', 'covariance'], tags=['603']),\n",
       " TaggedDocument(words=['sqlite'], tags=['604']),\n",
       " TaggedDocument(words=['virtual', 'machine', 'management'], tags=['605']),\n",
       " TaggedDocument(words=['concept', 'learning'], tags=['606']),\n",
       " TaggedDocument(words=['content', 'management'], tags=['607']),\n",
       " TaggedDocument(words=['coding', 'social', 'sciences'], tags=['608']),\n",
       " TaggedDocument(words=['ir', 'evaluation'], tags=['609']),\n",
       " TaggedDocument(words=['missing', 'data'], tags=['610']),\n",
       " TaggedDocument(words=['react', 'navigation'], tags=['611']),\n",
       " TaggedDocument(words=['scaleway'], tags=['612']),\n",
       " TaggedDocument(words=['apache', 'hbase'], tags=['613']),\n",
       " TaggedDocument(words=['mina'], tags=['614']),\n",
       " TaggedDocument(words=['compiler'], tags=['615']),\n",
       " TaggedDocument(words=['corner', 'detection'], tags=['616']),\n",
       " TaggedDocument(words=['outlier'], tags=['617']),\n",
       " TaggedDocument(words=['terraform'], tags=['618']),\n",
       " TaggedDocument(words=['logic', 'synthesis'], tags=['619']),\n",
       " TaggedDocument(words=['microcontroller'], tags=['620']),\n",
       " TaggedDocument(words=['clojure'], tags=['621']),\n",
       " TaggedDocument(words=['clicky'], tags=['622']),\n",
       " TaggedDocument(words=['intelligent', 'agent'], tags=['623']),\n",
       " TaggedDocument(words=['nats'], tags=['624']),\n",
       " TaggedDocument(words=['visual', 'basic'], tags=['625']),\n",
       " TaggedDocument(words=['postmark'], tags=['626']),\n",
       " TaggedDocument(words=['google', 'kubernetes', 'engine'], tags=['627']),\n",
       " TaggedDocument(words=['google', 'cloud', 'dataflow'], tags=['628']),\n",
       " TaggedDocument(words=['redundancy', 'engineering'], tags=['629']),\n",
       " TaggedDocument(words=['eureka'], tags=['630']),\n",
       " TaggedDocument(words=['dynamic', 'source', 'routing'], tags=['631']),\n",
       " TaggedDocument(words=['business'], tags=['632']),\n",
       " TaggedDocument(words=['motion', 'estimation'], tags=['633']),\n",
       " TaggedDocument(words=['operations', 'research'], tags=['634']),\n",
       " TaggedDocument(words=['mobile', 'interaction', 'design', 'tools'], tags=['635']),\n",
       " TaggedDocument(words=['polymer'], tags=['636']),\n",
       " TaggedDocument(words=['sencha', 'touch'], tags=['637']),\n",
       " TaggedDocument(words=['association', 'rule', 'learning'], tags=['638']),\n",
       " TaggedDocument(words=['cross', 'platform', 'mobile', 'development'], tags=['639']),\n",
       " TaggedDocument(words=['fusion'], tags=['640']),\n",
       " TaggedDocument(words=['human', 'visual', 'system', 'model'], tags=['641']),\n",
       " TaggedDocument(words=['internet', 'of', 'things', 'hardware'], tags=['642']),\n",
       " TaggedDocument(words=['deep', 'learning'], tags=['643']),\n",
       " TaggedDocument(words=['civil', 'engineering'], tags=['644']),\n",
       " TaggedDocument(words=['wagtail'], tags=['645']),\n",
       " TaggedDocument(words=['zepto'], tags=['646']),\n",
       " TaggedDocument(words=['website', 'monitoring'], tags=['647']),\n",
       " TaggedDocument(words=['predictive', 'coding'], tags=['648']),\n",
       " TaggedDocument(words=['divide', 'and', 'conquer', 'algorithms'], tags=['649']),\n",
       " TaggedDocument(words=['data', 'stream', 'mining'], tags=['650']),\n",
       " TaggedDocument(words=['browsersync'], tags=['651']),\n",
       " TaggedDocument(words=['search', 'as', 'a', 'service'], tags=['652']),\n",
       " TaggedDocument(words=['boosting', 'machine', 'learning'], tags=['653']),\n",
       " TaggedDocument(words=['motion', 'detection'], tags=['654']),\n",
       " TaggedDocument(words=['point', 'spread', 'function'], tags=['655']),\n",
       " TaggedDocument(words=['multivariate', 'analysis'], tags=['656']),\n",
       " TaggedDocument(words=['lexico'], tags=['657']),\n",
       " TaggedDocument(words=['engineering', 'ethics'], tags=['658']),\n",
       " TaggedDocument(words=['microframeworks'], tags=['659']),\n",
       " TaggedDocument(words=['decision', 'support', 'system'], tags=['660']),\n",
       " TaggedDocument(words=['stackdriver'], tags=['661']),\n",
       " TaggedDocument(words=['phoenix', 'framework'], tags=['662']),\n",
       " TaggedDocument(words=['protractor'], tags=['663']),\n",
       " TaggedDocument(words=['aws', 'codedeploy'], tags=['664']),\n",
       " TaggedDocument(words=['objective', 'c'], tags=['665']),\n",
       " TaggedDocument(words=['code', 'quality'], tags=['666']),\n",
       " TaggedDocument(words=['p', 'system'], tags=['667']),\n",
       " TaggedDocument(words=['emacs'], tags=['668']),\n",
       " TaggedDocument(words=['heroku', 'postgres'], tags=['669']),\n",
       " TaggedDocument(words=['data', 'science'], tags=['670']),\n",
       " TaggedDocument(words=['first', 'class'], tags=['671']),\n",
       " TaggedDocument(words=['video', 'quality'], tags=['672']),\n",
       " TaggedDocument(words=['external', 'data', 'representation'], tags=['673']),\n",
       " TaggedDocument(words=['leaflet'], tags=['674']),\n",
       " TaggedDocument(words=['amazon', 'elasticache'], tags=['675']),\n",
       " TaggedDocument(words=['scaffold'], tags=['676']),\n",
       " TaggedDocument(words=['ember.js'], tags=['677']),\n",
       " TaggedDocument(words=['mattermost'], tags=['678']),\n",
       " TaggedDocument(words=['database', 'transaction'], tags=['679']),\n",
       " TaggedDocument(words=['adaboost'], tags=['680']),\n",
       " TaggedDocument(words=['software', 'agent'], tags=['681']),\n",
       " TaggedDocument(words=['legal', 'information', 'retrieval'], tags=['682']),\n",
       " TaggedDocument(words=['aws', 'codebuild'], tags=['683']),\n",
       " TaggedDocument(words=['plagiarism', 'detection'], tags=['684']),\n",
       " TaggedDocument(words=['front', 'and', 'back', 'ends'], tags=['685']),\n",
       " TaggedDocument(words=['aurelia'], tags=['686']),\n",
       " TaggedDocument(words=['electrical', 'engineering'], tags=['687']),\n",
       " TaggedDocument(words=['responsive', 'design'], tags=['688']),\n",
       " TaggedDocument(words=['tools', 'for', 'github'], tags=['689']),\n",
       " TaggedDocument(words=['uptime', 'robot'], tags=['690']),\n",
       " TaggedDocument(words=['puppeteer'], tags=['691']),\n",
       " TaggedDocument(words=['node.js'], tags=['692']),\n",
       " TaggedDocument(words=['microframeworks', 'backend'], tags=['693']),\n",
       " TaggedDocument(words=['error', 'detection', 'and', 'correction'], tags=['694']),\n",
       " TaggedDocument(words=['wordnet'], tags=['695']),\n",
       " TaggedDocument(words=['lottie'], tags=['696']),\n",
       " TaggedDocument(words=['lxd'], tags=['697']),\n",
       " TaggedDocument(words=['wireless', 'sensor', 'network'], tags=['698']),\n",
       " TaggedDocument(words=['code', 'collaboration', 'and', 'version', 'control'], tags=['699']),\n",
       " TaggedDocument(words=['apache', 'subversion'], tags=['700']),\n",
       " TaggedDocument(words=['zeplin'], tags=['701']),\n",
       " TaggedDocument(words=['database', 'design'], tags=['702']),\n",
       " TaggedDocument(words=['adobe', 'phonegap'], tags=['703']),\n",
       " TaggedDocument(words=['random', 'indexing'], tags=['704']),\n",
       " TaggedDocument(words=['histogram'], tags=['705']),\n",
       " TaggedDocument(words=['dokku'], tags=['706']),\n",
       " TaggedDocument(words=['piwik'], tags=['707']),\n",
       " TaggedDocument(words=['mongodb'], tags=['708']),\n",
       " TaggedDocument(words=['graph', 'databases'], tags=['709']),\n",
       " TaggedDocument(words=['clone', 'java', 'method'], tags=['710']),\n",
       " TaggedDocument(words=['application', 'utilities'], tags=['711']),\n",
       " TaggedDocument(words=['graphite'], tags=['712']),\n",
       " TaggedDocument(words=['rabbitmq'], tags=['713']),\n",
       " TaggedDocument(words=['performance', 'prediction'], tags=['714']),\n",
       " TaggedDocument(words=['message', 'passing'], tags=['715']),\n",
       " TaggedDocument(words=['sqlalchemy'], tags=['716']),\n",
       " TaggedDocument(words=['time', 'to', 'market'], tags=['717']),\n",
       " TaggedDocument(words=['mobile', 'development'], tags=['718']),\n",
       " TaggedDocument(words=['operator', 'computer', 'programming'], tags=['719']),\n",
       " TaggedDocument(words=['softlayer'], tags=['720']),\n",
       " TaggedDocument(words=['tensorflow'], tags=['721']),\n",
       " TaggedDocument(words=['csharp'], tags=['722']),\n",
       " TaggedDocument(words=['link', 'analysis'], tags=['723']),\n",
       " TaggedDocument(words=['concurrency', 'control'], tags=['724']),\n",
       " TaggedDocument(words=['firebase', 'crashlytics'], tags=['725']),\n",
       " TaggedDocument(words=['distributed', 'algorithm'], tags=['726']),\n",
       " TaggedDocument(words=['concurrency', 'frameworks'], tags=['727']),\n",
       " TaggedDocument(words=['human', 'computer', 'interaction'], tags=['728']),\n",
       " TaggedDocument(words=['testing'], tags=['729']),\n",
       " TaggedDocument(words=['display', 'device'], tags=['730']),\n",
       " TaggedDocument(words=['top', 'down', 'model'], tags=['731']),\n",
       " TaggedDocument(words=['document', 'processing'], tags=['732']),\n",
       " TaggedDocument(words=['project', 'management'], tags=['733']),\n",
       " TaggedDocument(words=['web', 'crawler'], tags=['734']),\n",
       " TaggedDocument(words=['liquibase'], tags=['735']),\n",
       " TaggedDocument(words=['virtual', 'machine', 'platforms', '/', 'containers'], tags=['736']),\n",
       " TaggedDocument(words=['emotion', 'recognition'], tags=['737']),\n",
       " TaggedDocument(words=['consistency', 'model'], tags=['738']),\n",
       " TaggedDocument(words=['emulator'], tags=['739']),\n",
       " TaggedDocument(words=['data', 'extraction'], tags=['740']),\n",
       " TaggedDocument(words=['web', 'service', 'automation'], tags=['741']),\n",
       " TaggedDocument(words=['information', 'overload'], tags=['742']),\n",
       " TaggedDocument(words=['arbol'], tags=['743']),\n",
       " TaggedDocument(words=['k', 'd', 'tree'], tags=['744']),\n",
       " TaggedDocument(words=['analytics', 'integrator'], tags=['745']),\n",
       " TaggedDocument(words=['domain', 'registration'], tags=['746']),\n",
       " TaggedDocument(words=['hierarchical', 'database', 'model'], tags=['747']),\n",
       " TaggedDocument(words=['redux', 'thunk'], tags=['748']),\n",
       " TaggedDocument(words=['object', 'relational', 'mapper'], tags=['749']),\n",
       " TaggedDocument(words=['incapsula'], tags=['750']),\n",
       " TaggedDocument(words=['source', 'separation'], tags=['751']),\n",
       " TaggedDocument(words=['level', 'set'], tags=['752']),\n",
       " TaggedDocument(words=['systems', 'management'], tags=['753']),\n",
       " TaggedDocument(words=['vault'], tags=['754']),\n",
       " TaggedDocument(words=['crazy', 'egg'], tags=['755']),\n",
       " TaggedDocument(words=['google', 'bigquery'], tags=['756']),\n",
       " TaggedDocument(words=['cassandra'], tags=['757']),\n",
       " TaggedDocument(words=['eye', 'tracking'], tags=['758']),\n",
       " TaggedDocument(words=['digital', 'signal', 'processing'], tags=['759']),\n",
       " TaggedDocument(words=['amazon', 'sns'], tags=['760']),\n",
       " TaggedDocument(words=['text', 'retrieval', 'conference'], tags=['761']),\n",
       " TaggedDocument(words=['gsm'], tags=['762']),\n",
       " TaggedDocument(words=['linear', 'logic'], tags=['763']),\n",
       " TaggedDocument(words=['field', 'programmable', 'gate', 'array'], tags=['764']),\n",
       " TaggedDocument(words=['static', 'site', 'generators'], tags=['765']),\n",
       " TaggedDocument(words=['telecommunications'], tags=['766']),\n",
       " TaggedDocument(words=['optical', 'recording'], tags=['767']),\n",
       " TaggedDocument(words=['heatmap', 'analytics'], tags=['768']),\n",
       " TaggedDocument(words=['server'], tags=['769']),\n",
       " TaggedDocument(words=['phantomjs'], tags=['770']),\n",
       " TaggedDocument(words=['java'], tags=['771']),\n",
       " TaggedDocument(words=['loggly'], tags=['772']),\n",
       " TaggedDocument(words=['variables'], tags=['773']),\n",
       " TaggedDocument(words=['amplitude'], tags=['774']),\n",
       " TaggedDocument(words=['parsing'], tags=['775']),\n",
       " TaggedDocument(words=['vuex'], tags=['776']),\n",
       " TaggedDocument(words=['phalcon'], tags=['777']),\n",
       " TaggedDocument(words=['computer', 'program'], tags=['778']),\n",
       " TaggedDocument(words=['continuous', 'integration'], tags=['779']),\n",
       " TaggedDocument(words=['database'], tags=['780']),\n",
       " TaggedDocument(words=['feature', 'selection'], tags=['781']),\n",
       " TaggedDocument(words=['parallel', 'computing'], tags=['782']),\n",
       " TaggedDocument(words=['sorting'], tags=['783']),\n",
       " TaggedDocument(words=['chemical', 'engineering'], tags=['784']),\n",
       " TaggedDocument(words=['cloudinary'], tags=['785']),\n",
       " TaggedDocument(words=['location', 'based', 'service'], tags=['786']),\n",
       " TaggedDocument(words=['clever', 'cloud'], tags=['787']),\n",
       " TaggedDocument(words=['computation'], tags=['788']),\n",
       " TaggedDocument(words=['wix'], tags=['789']),\n",
       " TaggedDocument(words=['codebook'], tags=['790']),\n",
       " TaggedDocument(words=['password', 'management'], tags=['791']),\n",
       " TaggedDocument(words=['intelligent', 'document', 'processing'], tags=['792']),\n",
       " TaggedDocument(words=['real', 'time', 'computing'], tags=['793']),\n",
       " TaggedDocument(words=['multi', 'core', 'processor'], tags=['794']),\n",
       " TaggedDocument(words=['solr'], tags=['795']),\n",
       " TaggedDocument(words=['cloud9', 'ide'], tags=['796']),\n",
       " TaggedDocument(words=['digitalocean'], tags=['797']),\n",
       " TaggedDocument(words=['browserstack'], tags=['798']),\n",
       " TaggedDocument(words=['travelling', 'salesman', 'problem'], tags=['799']),\n",
       " TaggedDocument(words=['scrutinizer'], tags=['800']),\n",
       " TaggedDocument(words=['hypercube'], tags=['801']),\n",
       " TaggedDocument(words=['fedora'], tags=['802']),\n",
       " TaggedDocument(words=['technological', 'change'], tags=['803']),\n",
       " TaggedDocument(words=['data', 'processing'], tags=['804']),\n",
       " TaggedDocument(words=['curve', 'fitting'], tags=['805']),\n",
       " TaggedDocument(words=['go'], tags=['806']),\n",
       " TaggedDocument(words=['visual', 'inspection'], tags=['807']),\n",
       " TaggedDocument(words=['sentiment', 'analysis'], tags=['808']),\n",
       " TaggedDocument(words=['nuclear', 'engineering'], tags=['809']),\n",
       " TaggedDocument(words=['xcode'], tags=['810']),\n",
       " TaggedDocument(words=['floating', 'point'], tags=['811']),\n",
       " TaggedDocument(words=['ant', 'design'], tags=['812']),\n",
       " TaggedDocument(words=['discrete', 'system'], tags=['813']),\n",
       " TaggedDocument(words=['spreadsheets', 'as', 'a', 'backend'], tags=['814']),\n",
       " TaggedDocument(words=['cpp'], tags=['815']),\n",
       " TaggedDocument(words=['jetty'], tags=['816']),\n",
       " TaggedDocument(words=['code', 'coverage'], tags=['817']),\n",
       " TaggedDocument(words=['database', 'tools'], tags=['818']),\n",
       " TaggedDocument(words=['enterprise', 'system'], tags=['819']),\n",
       " TaggedDocument(words=['generalized', 'linear', 'model'], tags=['820']),\n",
       " TaggedDocument(words=['combinatorial', 'optimization'], tags=['821']),\n",
       " TaggedDocument(words=['data', 'integration'], tags=['822']),\n",
       " TaggedDocument(words=['naive', 'bayes', 'classifier'], tags=['823']),\n",
       " TaggedDocument(words=['transparency', 'graphic'], tags=['824']),\n",
       " TaggedDocument(words=['data', 'validation'], tags=['825']),\n",
       " TaggedDocument(words=['multidimensional', 'analysis'], tags=['826']),\n",
       " TaggedDocument(words=['javascript', 'testing', 'framework'], tags=['827']),\n",
       " TaggedDocument(words=['iframely'], tags=['828']),\n",
       " TaggedDocument(words=['rdf'], tags=['829']),\n",
       " TaggedDocument(words=['scripting', 'language'], tags=['830']),\n",
       " TaggedDocument(words=['communications', 'sdk'], tags=['831']),\n",
       " TaggedDocument(words=['puma'], tags=['832']),\n",
       " TaggedDocument(words=['devops'], tags=['833']),\n",
       " TaggedDocument(words=['key', 'exchange'], tags=['834']),\n",
       " TaggedDocument(words=['charting', 'libraries'], tags=['835']),\n",
       " TaggedDocument(words=['matched', 'filter'], tags=['836']),\n",
       " TaggedDocument(words=['pico', '8'], tags=['837']),\n",
       " TaggedDocument(words=['remote', 'control'], tags=['838']),\n",
       " TaggedDocument(words=['independent', 'set'], tags=['839']),\n",
       " TaggedDocument(words=['semantic', 'html'], tags=['840']),\n",
       " TaggedDocument(words=['browserify'], tags=['841']),\n",
       " TaggedDocument(words=['business', 'administration'], tags=['842']),\n",
       " TaggedDocument(words=['hash', 'function'], tags=['843']),\n",
       " TaggedDocument(words=['structured', 'text'], tags=['844']),\n",
       " TaggedDocument(words=['socket.io'], tags=['845']),\n",
       " TaggedDocument(words=['access', 'network'], tags=['846']),\n",
       " TaggedDocument(words=['bot'], tags=['847']),\n",
       " TaggedDocument(words=['search', 'engine'], tags=['848']),\n",
       " TaggedDocument(words=['mustache'], tags=['849']),\n",
       " TaggedDocument(words=['integer', 'programming'], tags=['850']),\n",
       " TaggedDocument(words=['dynamic', 'time', 'warping'], tags=['851']),\n",
       " TaggedDocument(words=['mailchimp'], tags=['852']),\n",
       " TaggedDocument(words=['unified', 'medical', 'language', 'system'], tags=['853']),\n",
       " TaggedDocument(words=['mongoose'], tags=['854']),\n",
       " TaggedDocument(words=['web', 'app', 'builders'], tags=['855']),\n",
       " TaggedDocument(words=['algolia'], tags=['856']),\n",
       " TaggedDocument(words=['portainer'], tags=['857']),\n",
       " TaggedDocument(words=['optical', 'disc'], tags=['858']),\n",
       " TaggedDocument(words=['automatic', 'taxonomy', 'induction'], tags=['859']),\n",
       " TaggedDocument(words=['data', 'structure'], tags=['860']),\n",
       " TaggedDocument(words=['automotive', 'engineering'], tags=['861']),\n",
       " TaggedDocument(words=['godaddy'], tags=['862']),\n",
       " TaggedDocument(words=['ifttt'], tags=['863']),\n",
       " TaggedDocument(words=['firebase'], tags=['864']),\n",
       " TaggedDocument(words=['google', 'cloud', 'functions'], tags=['865']),\n",
       " TaggedDocument(words=['chartbeat'], tags=['866']),\n",
       " TaggedDocument(words=['discrete', 'logarithm'], tags=['867']),\n",
       " TaggedDocument(words=['atom'], tags=['868']),\n",
       " TaggedDocument(words=['runscope'], tags=['869']),\n",
       " TaggedDocument(words=['correlation', 'coefficient'], tags=['870']),\n",
       " TaggedDocument(words=['control', 'theory'], tags=['871']),\n",
       " TaggedDocument(words=['customer', 'relationship', 'management'], tags=['872']),\n",
       " TaggedDocument(words=['terminal'], tags=['873']),\n",
       " TaggedDocument(words=['diagram'], tags=['874']),\n",
       " TaggedDocument(words=['prestashop'], tags=['875']),\n",
       " TaggedDocument(words=['program', 'optimization'], tags=['876']),\n",
       " TaggedDocument(words=['base', 'station'], tags=['877']),\n",
       " TaggedDocument(words=['passenger'], tags=['878']),\n",
       " TaggedDocument(words=['deontic', 'logic'], tags=['879']),\n",
       " TaggedDocument(words=['big', 'data'], tags=['880']),\n",
       " TaggedDocument(words=['fossa'], tags=['881']),\n",
       " TaggedDocument(words=['chrome'], tags=['882']),\n",
       " TaggedDocument(words=['application', 'programming', 'interface'], tags=['883']),\n",
       " TaggedDocument(words=['unicorn'], tags=['884']),\n",
       " TaggedDocument(words=['funnel', 'analysis', 'analytics'], tags=['885']),\n",
       " TaggedDocument(words=['mobile', 'agent'], tags=['886']),\n",
       " TaggedDocument(words=['octopus', 'deploy'], tags=['887']),\n",
       " TaggedDocument(words=['adobe', 'photoshop'], tags=['888']),\n",
       " TaggedDocument(words=['path', 'analysis', 'statistics'], tags=['889']),\n",
       " TaggedDocument(words=['google', 'cloud', 'pubsub'], tags=['890']),\n",
       " TaggedDocument(words=['heroku', 'redis'], tags=['891']),\n",
       " TaggedDocument(words=['duplicate', 'content'], tags=['892']),\n",
       " TaggedDocument(words=['statuscake'], tags=['893']),\n",
       " TaggedDocument(words=['media', 'access', 'control'], tags=['894']),\n",
       " TaggedDocument(words=['kanban', 'for', 'github', 'issues'], tags=['895']),\n",
       " TaggedDocument(words=['environmental', 'engineering'], tags=['896']),\n",
       " TaggedDocument(words=['flask'], tags=['897']),\n",
       " TaggedDocument(words=['systems', 'engineering'], tags=['898']),\n",
       " TaggedDocument(words=['logic', 'in', 'computer', 'science'], tags=['899']),\n",
       " TaggedDocument(words=['cdnjs'], tags=['900']),\n",
       " TaggedDocument(words=['data', 'compression'], tags=['901']),\n",
       " TaggedDocument(words=['independent', 'component', 'analysis'], tags=['902']),\n",
       " TaggedDocument(words=['file', 'system'], tags=['903']),\n",
       " TaggedDocument(words=['decomposition', 'method', 'constraint', 'satisfaction'], tags=['904']),\n",
       " TaggedDocument(words=['chemometrics'], tags=['905']),\n",
       " TaggedDocument(words=['cloud', 'content', 'management', 'system'], tags=['906']),\n",
       " TaggedDocument(words=['domain', 'model'], tags=['907']),\n",
       " TaggedDocument(words=['email', 'testing'], tags=['908']),\n",
       " TaggedDocument(words=['feature', 'extraction'], tags=['909']),\n",
       " TaggedDocument(words=['numpy'], tags=['910']),\n",
       " TaggedDocument(words=['finance'], tags=['911']),\n",
       " TaggedDocument(words=['biological', 'database'], tags=['912']),\n",
       " TaggedDocument(words=['security'], tags=['913']),\n",
       " TaggedDocument(words=['predictive', 'value'], tags=['914']),\n",
       " TaggedDocument(words=['collaboration'], tags=['915']),\n",
       " TaggedDocument(words=['commerce'], tags=['916']),\n",
       " TaggedDocument(words=['smart', 'information', 'retrieval', 'system'], tags=['917']),\n",
       " TaggedDocument(words=['mesh', 'networking'], tags=['918']),\n",
       " TaggedDocument(words=['computational', 'model'], tags=['919']),\n",
       " TaggedDocument(words=['cryptography'], tags=['920']),\n",
       " TaggedDocument(words=['non', 'volatile', 'memory'], tags=['921']),\n",
       " TaggedDocument(words=['thread', 'computing'], tags=['922']),\n",
       " TaggedDocument(words=['windows'], tags=['923']),\n",
       " TaggedDocument(words=['geometric', 'modeling'], tags=['924']),\n",
       " TaggedDocument(words=['metis'], tags=['925']),\n",
       " TaggedDocument(words=['frequency', 'domain'], tags=['926']),\n",
       " TaggedDocument(words=['onsen', 'ui'], tags=['927']),\n",
       " TaggedDocument(words=['travis', 'ci'], tags=['928']),\n",
       " TaggedDocument(words=['markov', 'chain'], tags=['929']),\n",
       " TaggedDocument(words=['throughput'], tags=['930']),\n",
       " TaggedDocument(words=['computational', 'complexity', 'theory'], tags=['931']),\n",
       " TaggedDocument(words=['mailgun'], tags=['932']),\n",
       " TaggedDocument(words=['data', 'classification'], tags=['933']),\n",
       " TaggedDocument(words=['look', 'ahead'], tags=['934']),\n",
       " TaggedDocument(words=['dempstershafer', 'theory'], tags=['935']),\n",
       " TaggedDocument(words=['azure', 'cosmos', 'db'], tags=['936']),\n",
       " TaggedDocument(words=['stream', 'processing'], tags=['937']),\n",
       " TaggedDocument(words=['amazon', 'rds', 'for', 'aurora'], tags=['938']),\n",
       " TaggedDocument(words=['cross', 'platform', 'desktop', 'development'], tags=['939']),\n",
       " TaggedDocument(words=['django', 'rest', 'framework'], tags=['940']),\n",
       " TaggedDocument(words=['queueing', 'theory'], tags=['941']),\n",
       " TaggedDocument(words=['computer', 'hardware'], tags=['942']),\n",
       " TaggedDocument(words=['component'], tags=['943']),\n",
       " TaggedDocument(words=['continuum', 'design', 'consultancy'], tags=['944']),\n",
       " TaggedDocument(words=['rubymine'], tags=['945']),\n",
       " TaggedDocument(words=['bourbon'], tags=['946']),\n",
       " TaggedDocument(words=['intellij', 'idea'], tags=['947']),\n",
       " TaggedDocument(words=['knowledge', 'acquisition'], tags=['948']),\n",
       " TaggedDocument(words=['docker', 'compose'], tags=['949']),\n",
       " TaggedDocument(words=['process', 'management'], tags=['950']),\n",
       " TaggedDocument(words=['data', 'center'], tags=['951']),\n",
       " TaggedDocument(words=['internetworking'], tags=['952']),\n",
       " TaggedDocument(words=['uglifyjs'], tags=['953']),\n",
       " TaggedDocument(words=['economic', 'policy'], tags=['954']),\n",
       " TaggedDocument(words=['mvc'], tags=['955']),\n",
       " TaggedDocument(words=['computability', 'theory'], tags=['956']),\n",
       " TaggedDocument(words=['convergence', 'routing'], tags=['957']),\n",
       " TaggedDocument(words=['mean', 'shift'], tags=['958']),\n",
       " TaggedDocument(words=['type', 'inference'], tags=['959']),\n",
       " TaggedDocument(words=['fabric', 'by', 'twitter'], tags=['960']),\n",
       " TaggedDocument(words=['frequency', 'analysis'], tags=['961']),\n",
       " TaggedDocument(words=['system', 'on', 'a', 'chip'], tags=['962']),\n",
       " TaggedDocument(words=['distributed', 'object'], tags=['963']),\n",
       " TaggedDocument(words=['woocommerce'], tags=['964']),\n",
       " TaggedDocument(words=['onesignal'], tags=['965']),\n",
       " TaggedDocument(words=['automated', 'reasoning'], tags=['966']),\n",
       " TaggedDocument(words=['pug'], tags=['967']),\n",
       " TaggedDocument(words=['distributed', 'file', 'system'], tags=['968']),\n",
       " TaggedDocument(words=['relational', 'database'], tags=['969']),\n",
       " TaggedDocument(words=['aws'], tags=['970']),\n",
       " TaggedDocument(words=['nosql'], tags=['971']),\n",
       " TaggedDocument(words=['dyn'], tags=['972']),\n",
       " TaggedDocument(words=['source', 'code', 'management', 'desktop', 'apps'], tags=['973']),\n",
       " TaggedDocument(words=['computational', 'science'], tags=['974']),\n",
       " TaggedDocument(words=['semantic', 'matching'], tags=['975']),\n",
       " TaggedDocument(words=['visual', 'cortex'], tags=['976']),\n",
       " TaggedDocument(words=['mobile', 'telephony'], tags=['977']),\n",
       " TaggedDocument(words=['json', 'server'], tags=['978']),\n",
       " TaggedDocument(words=['in', 'memory', 'databases'], tags=['979']),\n",
       " TaggedDocument(words=['laravel'], tags=['980']),\n",
       " TaggedDocument(words=['electronic', 'data', 'interchange'], tags=['981']),\n",
       " TaggedDocument(words=['intercom'], tags=['982']),\n",
       " TaggedDocument(words=['secure', 'multi', 'party', 'computation'], tags=['983']),\n",
       " TaggedDocument(words=['jira'], tags=['984']),\n",
       " TaggedDocument(words=['multi', 'agent', 'system'], tags=['985']),\n",
       " TaggedDocument(words=['latent', 'semantic', 'indexing'], tags=['986']),\n",
       " TaggedDocument(words=['airtable'], tags=['987']),\n",
       " TaggedDocument(words=['recursion'], tags=['988']),\n",
       " TaggedDocument(words=['user', 'interface'], tags=['989']),\n",
       " TaggedDocument(words=['ngrok'], tags=['990']),\n",
       " TaggedDocument(words=['sequential', 'pattern', 'mining'], tags=['991']),\n",
       " TaggedDocument(words=['crowdsourcing'], tags=['992']),\n",
       " TaggedDocument(words=['flyway'], tags=['993']),\n",
       " TaggedDocument(words=['photogrammetry'], tags=['994']),\n",
       " TaggedDocument(words=['aws', 'direct', 'connect'], tags=['995']),\n",
       " TaggedDocument(words=['quality', 'assurance'], tags=['996']),\n",
       " TaggedDocument(words=['buildkite'], tags=['997']),\n",
       " TaggedDocument(words=['internet', 'privacy'], tags=['998']),\n",
       " TaggedDocument(words=['containers'], tags=['999']),\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 1/40\n",
      "Training epoch 2/40\n",
      "Training epoch 3/40\n",
      "Training epoch 4/40\n",
      "Training epoch 5/40\n",
      "Training epoch 6/40\n",
      "Training epoch 7/40\n",
      "Training epoch 8/40\n",
      "Training epoch 9/40\n",
      "Training epoch 10/40\n",
      "Training epoch 11/40\n",
      "Training epoch 12/40\n",
      "Training epoch 13/40\n",
      "Training epoch 14/40\n",
      "Training epoch 15/40\n",
      "Training epoch 16/40\n",
      "Training epoch 17/40\n",
      "Training epoch 18/40\n",
      "Training epoch 19/40\n",
      "Training epoch 20/40\n",
      "Training epoch 21/40\n",
      "Training epoch 22/40\n",
      "Training epoch 23/40\n",
      "Training epoch 24/40\n",
      "Training epoch 25/40\n",
      "Training epoch 26/40\n",
      "Training epoch 27/40\n",
      "Training epoch 28/40\n",
      "Training epoch 29/40\n",
      "Training epoch 30/40\n",
      "Training epoch 31/40\n",
      "Training epoch 32/40\n",
      "Training epoch 33/40\n",
      "Training epoch 34/40\n",
      "Training epoch 35/40\n",
      "Training epoch 36/40\n",
      "Training epoch 37/40\n",
      "Training epoch 38/40\n",
      "Training epoch 39/40\n",
      "Training epoch 40/40\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(model.epochs):\n",
    "    print(f\"Training epoch {epoch+1}/{model.epochs}\")\n",
    "    model.train(tagged_data, \n",
    "                total_examples=model.corpus_count, \n",
    "                epochs=model.epochs)\n",
    "\n",
    "model.save('cv_job_maching.model')\n",
    "print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumberNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading pdfplumber-0.10.3-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting pdfminer.six==20221105 (from pdfplumber)\n",
      "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
      "     ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/5.6 MB 1.3 MB/s eta 0:00:05\n",
      "     ---------------------------------------- 0.1/5.6 MB 812.7 kB/s eta 0:00:07\n",
      "      --------------------------------------- 0.1/5.6 MB 655.4 kB/s eta 0:00:09\n",
      "     - -------------------------------------- 0.2/5.6 MB 833.5 kB/s eta 0:00:07\n",
      "     - -------------------------------------- 0.2/5.6 MB 926.0 kB/s eta 0:00:06\n",
      "     - -------------------------------------- 0.2/5.6 MB 808.4 kB/s eta 0:00:07\n",
      "     -- ------------------------------------- 0.3/5.6 MB 883.3 kB/s eta 0:00:07\n",
      "     -- ------------------------------------- 0.3/5.6 MB 936.6 kB/s eta 0:00:06\n",
      "     -- ------------------------------------- 0.3/5.6 MB 832.3 kB/s eta 0:00:07\n",
      "     --- ------------------------------------ 0.5/5.6 MB 1.0 MB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 0.6/5.6 MB 1.2 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 0.7/5.6 MB 1.3 MB/s eta 0:00:04\n",
      "     ----- ---------------------------------- 0.8/5.6 MB 1.4 MB/s eta 0:00:04\n",
      "     ------ --------------------------------- 0.9/5.6 MB 1.4 MB/s eta 0:00:04\n",
      "     ------- -------------------------------- 1.0/5.6 MB 1.4 MB/s eta 0:00:04\n",
      "     ------- -------------------------------- 1.1/5.6 MB 1.5 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 1.2/5.6 MB 1.5 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 1.3/5.6 MB 1.5 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 1.4/5.6 MB 1.5 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 1.5/5.6 MB 1.5 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 1.5/5.6 MB 1.5 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 1.5/5.6 MB 1.5 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 1.5/5.6 MB 1.5 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 1.5/5.6 MB 1.5 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 1.5/5.6 MB 1.5 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 1.5/5.6 MB 1.5 MB/s eta 0:00:03\n",
      "     ----------- ---------------------------- 1.5/5.6 MB 1.2 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 1.6/5.6 MB 1.2 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 1.6/5.6 MB 1.2 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 1.6/5.6 MB 1.2 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 1.6/5.6 MB 1.2 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 1.6/5.6 MB 1.2 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 1.6/5.6 MB 1.2 MB/s eta 0:00:04\n",
      "     ------------ --------------------------- 1.7/5.6 MB 1.1 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 1.9/5.6 MB 1.2 MB/s eta 0:00:04\n",
      "     -------------- ------------------------- 2.0/5.6 MB 1.2 MB/s eta 0:00:04\n",
      "     -------------------- ------------------- 2.8/5.6 MB 1.6 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 2.9/5.6 MB 1.6 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 3.0/5.6 MB 1.6 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 3.1/5.6 MB 1.6 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 3.1/5.6 MB 1.6 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 3.1/5.6 MB 1.6 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 3.1/5.6 MB 1.6 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 3.1/5.6 MB 1.6 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 3.1/5.6 MB 1.6 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 3.1/5.6 MB 1.6 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 3.1/5.6 MB 1.4 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 3.3/5.6 MB 1.4 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 3.4/5.6 MB 1.4 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 3.5/5.6 MB 1.5 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 3.6/5.6 MB 1.5 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 3.7/5.6 MB 1.5 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 3.7/5.6 MB 1.5 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 3.9/5.6 MB 1.5 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 3.9/5.6 MB 1.5 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 4.0/5.6 MB 1.5 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 4.1/5.6 MB 1.5 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 4.1/5.6 MB 1.5 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 4.2/5.6 MB 1.5 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 4.4/5.6 MB 1.5 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 4.5/5.6 MB 1.5 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 4.5/5.6 MB 1.5 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 4.6/5.6 MB 1.5 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 4.7/5.6 MB 1.5 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 4.8/5.6 MB 1.6 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 4.9/5.6 MB 1.6 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 4.9/5.6 MB 1.5 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 4.9/5.6 MB 1.5 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 4.9/5.6 MB 1.5 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 4.9/5.6 MB 1.5 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 4.9/5.6 MB 1.5 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 4.9/5.6 MB 1.5 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 4.9/5.6 MB 1.5 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 5.1/5.6 MB 1.4 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 5.2/5.6 MB 1.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  5.6/5.6 MB 1.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 5.6/5.6 MB 1.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pdfplumber) (10.1.0)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
      "  Downloading pypdfium2-4.25.0-py3-none-win_amd64.whl.metadata (47 kB)\n",
      "     ---------------------------------------- 0.0/47.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 47.8/47.8 kB 1.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pdfminer.six==20221105->pdfplumber) (3.3.2)\n",
      "Collecting cryptography>=36.0.0 (from pdfminer.six==20221105->pdfplumber)\n",
      "  Downloading cryptography-41.0.7-cp37-abi3-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting cffi>=1.12 (from cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber)\n",
      "  Downloading cffi-1.16.0-cp312-cp312-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting pycparser (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber)\n",
      "  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "     ---------------------------------------- 0.0/118.7 kB ? eta -:--:--\n",
      "     ------------------------------------ - 112.6/118.7 kB 3.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- 118.7/118.7 kB 2.3 MB/s eta 0:00:00\n",
      "Downloading pdfplumber-0.10.3-py3-none-any.whl (48 kB)\n",
      "   ---------------------------------------- 0.0/49.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 49.0/49.0 kB 1.2 MB/s eta 0:00:00\n",
      "Downloading pypdfium2-4.25.0-py3-none-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/2.7 MB 5.5 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 0.2/2.7 MB 2.9 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.4/2.7 MB 3.8 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.4/2.7 MB 3.8 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.5/2.7 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.7/2.7 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.7/2.7 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.8/2.7 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.9/2.7 MB 2.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 1.0/2.7 MB 2.2 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 1.1/2.7 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.2/2.7 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.2/2.7 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.3/2.7 MB 2.0 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.4/2.7 MB 2.0 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.5/2.7 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.6/2.7 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.7/2.7 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.7/2.7 MB 2.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.8/2.7 MB 2.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.9/2.7 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 2.0/2.7 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 2.1/2.7 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 2.1/2.7 MB 1.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 2.2/2.7 MB 1.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.3/2.7 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 2.4/2.7 MB 1.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.5/2.7 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.5/2.7 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.6/2.7 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 1.9 MB/s eta 0:00:00\n",
      "Downloading cryptography-41.0.7-cp37-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.1/2.7 MB 1.7 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.2/2.7 MB 1.5 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.3/2.7 MB 2.1 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.4/2.7 MB 2.2 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.4/2.7 MB 2.0 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.6/2.7 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.7/2.7 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.8/2.7 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.9/2.7 MB 2.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 1.0/2.7 MB 2.2 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 1.0/2.7 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.1/2.7 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.2/2.7 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.3/2.7 MB 2.0 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.4/2.7 MB 2.0 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.4/2.7 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.5/2.7 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.5/2.7 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.5/2.7 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.5/2.7 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.5/2.7 MB 2.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.0/2.7 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 2.1/2.7 MB 1.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 2.2/2.7 MB 1.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.2/2.7 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 2.3/2.7 MB 1.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.4/2.7 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.5/2.7 MB 1.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.6/2.7 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 1.8 MB/s eta 0:00:00\n",
      "Downloading cffi-1.16.0-cp312-cp312-win_amd64.whl (181 kB)\n",
      "   ---------------------------------------- 0.0/182.0 kB ? eta -:--:--\n",
      "   --------------------------- ------------ 122.9/182.0 kB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 182.0/182.0 kB 2.2 MB/s eta 0:00:00\n",
      "Installing collected packages: pypdfium2, pycparser, cffi, cryptography, pdfminer.six, pdfplumber\n",
      "Successfully installed cffi-1.16.0 cryptography-41.0.7 pdfminer.six-20221105 pdfplumber-0.10.3 pycparser-2.21 pypdfium2-4.25.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script pypdfium2.exe is installed in 'c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script pdfplumber.exe is installed in 'c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pdfplumber\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf = PyPDF2.PdfReader('./kainat.pdf')\n",
    "# resume = \"\"\n",
    "# for i in range(len(pdf.pages)):\n",
    "#     pageObj = pdf.pages[i]\n",
    "#     resume += pageObj.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "resume = \"\"\n",
    "with pdfplumber.open('./CV_sample.pdf') as pdf:\n",
    "    for page in pdf.pages:\n",
    "        resume += page.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Nisa Nadeem\\nLahore, Pakistan nisanadeem90@gmail.com +92 3094283955 in/nisa-nadeem-16aa08227\\nSUMMARY\\nAn independent learner, detail-oriented and a team player with fundamental knowledge of\\nsoftware design and development in creating and executing innovative software solution in a\\ndeadline-driven environment to enhance business productivity.\\nEXPERIENCE\\nStudent Ambassador|Tkxel|Pakistan, Lahore|August 2023- Present\\nAs a Student Ambassador at Tkxel, I e\\x00ectively represented the organization's values and engaged with diverse audiences, showcasing the\\ncompany's innovations and fostering meaningful connections within the student community.\\nTeaching Assistant|FAST NUCES Lahore|January 2022 - June 2023\\nContent Writer|www.pakzilla.com/|Hybrid|August 2021 - December 2021\\nI honed my passion for technology and coding into engaging and informative content as I crafted articles for a tech-focused blog, delivering\\ncomplex concepts in an accessible and reader-friendly manner.\\nPROJECTS\\nJobify|Mongo, Express , React and Node|https://github.com/nisanadeem909/web2.git\\n A website to connect companies and applicants. It contains applicant's pro\\x00le with some unique features to compare the jobs and job\\nsuggestions according to the skills. Whereas company's pro\\x00le exhibit features to view all the applicants and their pro\\x00les. It also provides a\\nfree CV Maker with a user friendly interface.\\nWork Otter|Java Swing, MySQL|https://github.com/komalw2001/SCDWorkOtter.git\\nA software house management system which has some unique features to keep record of all employees, show promotion recommendations\\nthrough their recorded work progress of assigned task in each project. It also has a noticeboard for each project where they can communicate\\nand coordinate.\\nAssemblage|Html, CSS, Spring boot, Thymeleaf, MySQL\\nA website to help students \\x00nd the best universities and career options at intermediate level. A unique questionnaire to give the best suitable\\ncareer and university option according to their interests and secured marks. An easy approach to career advisors and all the relevant\\ninformation\\nEDUCATION\\nBachelor of Software Engineering|FAST NUCES |Lahore, Pakistan|2024\\nA Levels|Beaconhouse School System|Lahore, Pakistan|2020\\nO Levels|Beaconhouse School System| Lahore,Pakistan|2018\\nCERTIFICATIONS\\nDeans List Spring 2020|FAST NUCES|2020\\nSKILLS\\nFront End: React, HTML, CSS.\\nBackend: C#, Node.\\nData: Microsoft Sql Server.\\nMongo DB, Express JS, Node JS, React JS, Html, Css, Javascript, Java, C#, MySQL\\nReact Native\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JD by input text:\n",
    "#jd = \"Project Manager BS Computer Science/Software Engineering/Information Technology/Software Project Management What you'll do  Work closely with engineers, product managers, designers, researchers, business, operations, support and other key leaders to conceptualize cross-functional initiatives with layers of dependencies, and plan their execution.Focus areas for your programs will include building new product features, expanding platform capability, overall system scalability & reliability, and tooling enhancements that will improve a customer's experience.  Have a solid understanding of the architecture to exercise technical judgment as necessary  Set accountability through communication of progress transparency and visibility on the next set of actions and milestones  Manage resource allocation and risks to optimize delivery  You will manage expectations for all stakeholders from leadership to individual teams, possess strong problem solving and negotiation skills, and earn trust of partners and teams.  You understand engineers and enjoy working with them, building trust by developing strong technical domain knowledge that adds value beyond project management.  Youll develop processes to ensure teamwork is streamlined to manage complexity and optimized velocity. You are thoughtful about how and when to implement processes with a light touch and clear understanding of success with Abyan Capital  Continuously look for opportunities for optimizing pace and quality  Youll balance urgency and priority while moving the needle on multiple initiatives.\"\n",
    "#jd =\"iOS Developer  BS Computer Science/Software Engineering/Information Technology Looking for IOS Developer having to 3+ years of experience. Requirements:  Bachelors degree in Computer Science or Software Engineering.  Proven experience as an app developer.  Proficient in Objective-C, Swift, and Cocoa Touch.  Extensive experience with iOS Frameworks such as Core Data and Core Animation.  Knowledge of iOS back-end services.  Knowledge of Apples design principles and application interface guidelines.  Proficient in code versioning tools including Mercurial, Git, and SVN.  Knowledge of C-based libraries.  Familiarity with push notifications, APIs, and cloud messaging.  Experience with continuous integration.\"\n",
    "jd = \"Php  Laravel Developer BS Computer Science/Software Engineering/Information Technology Manafa tech requires a talented PHP Developer.  You must have very strong programming skills, specially in open source technologies (PHP Core and Frameworks CI, YII, Laravel, CakePHP, Zend) , JS libraries.  Must be graduate or master in computer sciences from reputable university  Personal Characteristics: Ability to work quickly but with a strong attention to detail and accuracy Team player and good interpersonal skills Ability to perform under stress and aggressive deadlines Self-organized with the ability to plan ahead Punctual and organized  Tools and Technologies :  PHP Core and Frameworks CI, YII, Laravel, CakePHP, Zend, Symphony  MySQL  JavaScript, Angular.js, JQuery, Node.js\"\n",
    "#jd = \"Graphic Designer-Ui/Ux Designer- Frontend Developer/designer The ideal candidates will have strong creative skills and a portfolio of work which demonstrates their passion. Bachelors BS Computer Science/Software Engineering/Information Technology    Skills Required: Photoshop, Illustrator/Corel Draw, AdobeXD, Figma and others within Adobe Creative Cloud Suite.  First-hand knowledge of: UX Design: An understanding/appreciation for UX Basic Coding: An understanding of how creative sits within digital platforms such as: HTML, CSS and JavaScript A good understanding of mobile first design  The ideal candidates will have strong creative skills and a portfolio of work which demonstrates their passion.  Basic Coding: An understanding of how creative sits within digital platforms such as: HTML, CSS and JavaScript A good understanding of mobile first design  Photoshop, Illustrator/Corel Draw, AdobeXD, Figma and others within Adobe Creative Cloud Suite. First-hand knowledge of: UX Design: An understanding/appreciation for UX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\]'\n",
      "<>:8: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\]'\n",
      "<>:8: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5756\\1993080037.py:2: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  resumeText = re.sub('http\\S+\\s*', ' ', resumeText)  # remove URLs\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5756\\1993080037.py:4: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  resumeText = re.sub('#\\S+', '', resumeText)  # remove hashtags\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5756\\1993080037.py:5: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  resumeText = re.sub('@\\S+', '  ', resumeText)  # remove mentions\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5756\\1993080037.py:6: SyntaxWarning: invalid escape sequence '\\]'\n",
      "  resumeText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', resumeText)  # remove punctuations\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5756\\1993080037.py:8: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  resumeText = re.sub('\\s+', ' ', resumeText)  # remove extra whitespace\n"
     ]
    }
   ],
   "source": [
    "def cleanResume(resumeText):\n",
    "    resumeText = re.sub('http\\S+\\s*', ' ', resumeText)  # remove URLs\n",
    "    resumeText = re.sub('RT|cc', ' ', resumeText)  # remove RT and cc\n",
    "    resumeText = re.sub('#\\S+', '', resumeText)  # remove hashtags\n",
    "    resumeText = re.sub('@\\S+', '  ', resumeText)  # remove mentions\n",
    "    resumeText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', resumeText)  # remove punctuations\n",
    "    resumeText = re.sub(r'[^\\x00-\\x7f]',r' ', resumeText) #removes non-printable characters\n",
    "    resumeText = re.sub('\\s+', ' ', resumeText)  # remove extra whitespace\n",
    "    # Remove numerical values from the text\n",
    "    resumeText = re.sub(r'\\d+', '', resumeText)\n",
    "\n",
    "    return resumeText.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_majors_by_spacy(doc):            \n",
    "        nlp = English()\n",
    "        patterns_path = \"majors.jsonl\"\n",
    "        ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "        ruler.from_disk(patterns_path)\n",
    "        \n",
    "        acceptable_majors_list = []\n",
    "        \n",
    "       \n",
    "        doc1 = nlp(doc)\n",
    "        acceptable_majors = []\n",
    "        for ent in doc1.ents:\n",
    "                labels_parts = ent.label_.split('|')\n",
    "                if labels_parts[0] == 'MAJOR':\n",
    "                    if labels_parts[2].replace('-', ' ') not in acceptable_majors:\n",
    "                        acceptable_majors.append(labels_parts[2].replace('-', ' '))\n",
    "                    if labels_parts[2].replace('-', ' ') not in acceptable_majors:\n",
    "                        acceptable_majors.append(labels_parts[2].replace('-', ' '))\n",
    "        if acceptable_majors:\n",
    "            acceptable_majors_list.append(', '.join(acceptable_majors))\n",
    "        \n",
    "        return acceptable_majors_list\n",
    "def match_degrees_by_spacy(doc):\n",
    "        nlp = English()\n",
    "        patterns_path = \"degrees.jsonl\"\n",
    "        ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "        ruler.from_disk(patterns_path)\n",
    "        acceptable_degrees_list = []\n",
    "        \n",
    "        \n",
    "        doc1 = nlp(doc)\n",
    "        degree_levels = []\n",
    "        for ent in doc1.ents:\n",
    "                labels_parts = ent.label_.split('|')\n",
    "                if labels_parts[0] == 'DEGREE':\n",
    "                    if labels_parts[1] not in degree_levels:\n",
    "                        degree_levels.append(labels_parts[1])\n",
    "        if degree_levels:\n",
    "                acceptable_degrees_list.append(', '.join(degree_levels))\n",
    "\n",
    "        return acceptable_degrees_list\n",
    "\n",
    "def match_skills_by_spacy(doc):\n",
    "        nlp = English()\n",
    "        patterns_path = \"skills.jsonl\"\n",
    "        ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "        ruler.from_disk(patterns_path)\n",
    "        acceptable_skills_list = []\n",
    "        \n",
    "        \n",
    "        doc1 = nlp(doc)\n",
    "        job_skills = []\n",
    "        for ent in doc1.ents:\n",
    "                labels_parts = ent.label_.split('|')\n",
    "                if labels_parts[0] == 'SKILL':\n",
    "                    if labels_parts[1].replace('-', ' ') not in job_skills:\n",
    "                        job_skills.append(labels_parts[1].replace('-', ' '))\n",
    "        if job_skills:\n",
    "                acceptable_skills_list.append(', '.join(job_skills))\n",
    "\n",
    "        return acceptable_skills_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_majors = match_majors_by_spacy(cleanResume(resume))\n",
    "cv_degrees = match_degrees_by_spacy(cleanResume(resume))\n",
    "cv_skills = match_skills_by_spacy(cleanResume(resume))\n",
    "\n",
    "cv_majors = [major.strip() for majors in cv_majors for major in majors.split(',')]\n",
    "cv_skills = [major.strip() for majors in cv_skills for major in majors.split(',')]\n",
    "cv_degrees = [major.strip() for majors in cv_degrees for major in majors.split(',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_all = cv_majors + cv_degrees + cv_skills\n",
    "\n",
    "cv_all = list(set(cv_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv_all = ' '.join(cv_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['backend',\n",
       " 'html',\n",
       " 'software engineering',\n",
       " 'business',\n",
       " 'react',\n",
       " 'css',\n",
       " 'software',\n",
       " 'frontend',\n",
       " 'design',\n",
       " 'expressjs',\n",
       " 'database',\n",
       " 'BS-LEVEL',\n",
       " 'java',\n",
       " 'react native',\n",
       " 'javascript',\n",
       " 'mysql',\n",
       " 'spring boot',\n",
       " 'microsoft sql server',\n",
       " 'content writing',\n",
       " 'node.js',\n",
       " 'code',\n",
       " 'spring',\n",
       " 'c']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_majors = match_majors_by_spacy(cleanResume(jd))\n",
    "jd_degrees = match_degrees_by_spacy(cleanResume(jd))\n",
    "jd_skills = match_skills_by_spacy(cleanResume(jd))\n",
    "\n",
    "jd_majors = [major.strip() for majors in jd_majors for major in majors.split(',')]\n",
    "jd_skills = [major.strip() for majors in jd_skills for major in majors.split(',')]\n",
    "jd_degrees = [major.strip() for majors in jd_degrees for major in majors.split(',')]\n",
    "\n",
    "jd_all = jd_majors + jd_degrees + jd_skills\n",
    "jd_all = list(set(jd_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jd_all = ' '.join(jd_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['javascript',\n",
       " 'yii',\n",
       " 'software engineering',\n",
       " 'mysql',\n",
       " 'zend framework',\n",
       " 'operations research',\n",
       " 'cakephp',\n",
       " 'programming',\n",
       " 'node.js',\n",
       " 'frameworks',\n",
       " 'information technology',\n",
       " 'angular',\n",
       " 'MS-LEVEL',\n",
       " 'BS-LEVEL',\n",
       " 'php',\n",
       " 'jquery',\n",
       " 'computer science',\n",
       " 'laravel']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jd_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "model = Doc2Vec.load('cv_job_maching.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# v1 = model.infer_vector(cv_all.split())\n",
    "# v2 = model.infer_vector(jd_all.split())\n",
    "# similarity = 100*(np.dot(np.array(v1), np.array(v2))) / (norm(np.array(v1)) * norm(np.array(v2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = []\n",
    "v2 = []\n",
    "\n",
    "for element in cv_all:\n",
    "    v1.append(model.infer_vector(element.split()))\n",
    "\n",
    "for element in jd_all:\n",
    "    v2.append(model.infer_vector(element.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = 0\n",
    "i = 0\n",
    "tot = 0\n",
    "if v1 != []:\n",
    "    for element in v2:\n",
    "        if jd_all[i] in cv_all:\n",
    "            similarity = similarity + 1\n",
    "            tot = tot + 1\n",
    "        else:\n",
    "            max = -1\n",
    "            for cv_item in v1:\n",
    "                newsimilarity = (np.dot(np.array(cv_item), np.array(element))) / (norm(np.array(cv_item)) * norm(np.array(element)))\n",
    "                if newsimilarity > max:\n",
    "                    max = newsimilarity\n",
    "            #print(max)\n",
    "            if max >= 0.3:\n",
    "                similarity = similarity + max\n",
    "                tot = tot + 1\n",
    "        # print(similarity)\n",
    "        #print(jd_all[i])\n",
    "        i=i+1\n",
    "        \n",
    "    if tot < len(jd_all)/2:\n",
    "        tot = len(jd_all)\n",
    "    \n",
    "    similarity = round(similarity/tot*100,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68.636"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.models import Word2Vec\n",
    "# from gensim.models import TfidfModel\n",
    "# from gensim.corpora import Dictionary\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# import numpy as np\n",
    "# from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def semantic_similarity_word2vec(job, resume, word2vec_model):\n",
    "#     # Tokenize the job and resume\n",
    "#     job_tokens = word_tokenize(job.lower())\n",
    "#     resume_tokens = word_tokenize(resume.lower())\n",
    "\n",
    "#     job_tokens= [token for token in job_tokens if token != ',']\n",
    "#     resume_tokens = [token for token in resume_tokens if token != ',']\n",
    "\n",
    "    \n",
    "    \n",
    "#     # Get the vectors for each token in the job and resume\n",
    "#     job_vectors = [word2vec_model.wv[word] for word in job_tokens if word in word2vec_model.wv]\n",
    "#     resume_vectors = [word2vec_model.wv[word] for word in resume_tokens if word in word2vec_model.wv]\n",
    "\n",
    "#     # Check if there are vectors available\n",
    "#     # if job_vectors and resume_vectors:\n",
    "#     #     # Average of vectors\n",
    "#     #     job_vector = np.mean(job_vectors, axis=0)\n",
    "#     #     resume_vector = np.mean(resume_vectors, axis=0)\n",
    "\n",
    "#     #     # Calculate cosine similarity\n",
    "#     #     similarity = 100 * np.dot(job_vector, resume_vector) / (norm(job_vector) * norm(resume_vector))\n",
    "\n",
    "#     #     return round(similarity, 3)\n",
    "#     # else:\n",
    "#     #     return \"No vectors found for one or both of the documents.\"\n",
    "#     score = 0\n",
    "#     for i in range(len(job_vectors)):\n",
    "        \n",
    "#         if any(np.isin(elem, resume_vectors) for elem in job_vectors[i]):\n",
    "#             score += 1\n",
    "#         else: # compares 1 word of JD with ALL CV words....jiski maximum cosine similarity..uska score uthata hai\n",
    "#             print(\"printing max = \")\n",
    "#             print(max(cosine_similarity([job_vectors[i]],resume_vectors)[0]))\n",
    "#             if max(cosine_similarity([job_vectors[i]],resume_vectors)[0]) >= 0.15:\n",
    "#                 score += max(cosine_similarity([job_vectors[i]],resume_vectors)[0])\n",
    "        \n",
    "#         print(job_tokens[i])\n",
    "#         print(score)\n",
    "#     score = score/len(job_vectors)  \n",
    "#     return round(score,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing max = \n",
      "0.17867742\n",
      "computer\n",
      "0.17867742478847504\n",
      "printing max = \n",
      "0.119518474\n",
      "science\n",
      "0.17867742478847504\n",
      "printing max = \n",
      "0.16964702\n",
      "software\n",
      "0.3483244478702545\n",
      "engineering\n",
      "1.3483244478702545\n",
      "information\n",
      "2.3483244478702545\n",
      "printing max = \n",
      "0.1948782\n",
      "technology\n",
      "2.54320265352726\n",
      "printing max = \n",
      "0.17867742\n",
      "bs-level\n",
      "2.721880078315735\n",
      "printing max = \n",
      "0.119518474\n",
      "graphic\n",
      "2.721880078315735\n",
      "printing max = \n",
      "0.16964702\n",
      "design\n",
      "2.8915271013975143\n",
      "user\n",
      "3.8915271013975143\n",
      "printing max = \n",
      "0.1948782\n",
      "interface\n",
      "4.08640530705452\n",
      "printing max = \n",
      "0.14729396\n",
      "frontend\n",
      "4.08640530705452\n",
      "printing max = \n",
      "0.25795498\n",
      "computer\n",
      "4.344360291957855\n",
      "Similarity between Job and Resume: 0.334\n"
     ]
    }
   ],
   "source": [
    "# # Example with one job description and one resume\n",
    "# job_description = jd_all\n",
    "# resume = cv_all\n",
    "\n",
    "# # Load your pre-trained Word2Vec model\n",
    "# word2vec_model = Word2Vec.load('./word2vec_model.model')  # Replace with the path to your saved model\n",
    "\n",
    "# similarity_score = semantic_similarity_word2vec(job_description, resume, word2vec_model)\n",
    "# print(f\"Similarity between Job and Resume: {similarity_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
